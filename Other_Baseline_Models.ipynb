{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Other Baseline Models.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "authorship_tag": "ABX9TyP9ZRnVkUlpdv8ha8biawPp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amyth18/CS598-Deep-Learning-Final-Project/blob/main/Other_Baseline_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i_en9fHp43m"
      },
      "outputs": [],
      "source": [
        "! pip install gensim --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJNa7v3lsRoA",
        "outputId": "beeb5fbf-de5a-4e7f-e9d4-2a901dc41de8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Yg41pDraqbIp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_PATH = \"/content/drive/My Drive/DLH Final Project\"\n",
        "DATASET_PATH = f\"{PROJECT_PATH}/mimic3/df_dataset_full_text.csv\"\n",
        "DATASET_D2V_PATH = f\"{PROJECT_PATH}/mimic3/df_dataset_full_text_d2v.csv\"\n",
        "DOC2VEC_PATH = f\"{PROJECT_PATH}/models/doc2vec.model\"\n",
        "W2V_MODEL_PATH = f\"{PROJECT_PATH}/models/word2vec.model\"\n",
        "\n",
        "TRAINING_BATCH_SIZE = 400\n",
        "MAX_WORDS = 1000\n",
        "W2V_EMB_SIZE = 128"
      ],
      "metadata": {
        "id": "lGz7aVYrqvJv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls \"/content/drive/My Drive/DLH Final Project/models\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F57y2QCLsIEq",
        "outputId": "3ca1743f-47cb-43d8-f843-ae1233f5e8eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doc2vec.model\t\t\tmain-model-27-04-2022-19-11-16\n",
            "doc2vec.model.syn1neg.npy\ttf-idf-27-04-2022-16-29-54\n",
            "doc2vec.model.wv.vectors.npy\tword2vec-27-04-2022-17-47-59\n",
            "main-model-27-04-2022-15-40-59\tword2vec.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "PuUIA2ZgBHuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset = pd.read_csv(DATASET_PATH, converters={'INPUT_TEXT': eval, \n",
        "                                                   'ICD9_CODE': eval})"
      ],
      "metadata": {
        "id": "ivuKcLL6qYzN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "docs = [TaggedDocument(doc, [i])\n",
        "        for i, doc in enumerate(df_dataset.INPUT_TEXT)]\n",
        "\n",
        "model = Doc2Vec(vector_size=128, window=2, \n",
        "                min_count=1, \n",
        "                workers=8, \n",
        "                epochs = 40)\n",
        "\n",
        "model.build_vocab(docs)\n",
        "\n",
        "model.train(docs, total_examples=model.corpus_count, \n",
        "            epochs=model.epochs)"
      ],
      "metadata": {
        "id": "2z6DqEnOt08a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(DOC2VEC_PATH)"
      ],
      "metadata": {
        "id": "3R8qX4qxyMlu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_doc2vec = [model.infer_vector(df_dataset['INPUT_TEXT'][i]) \n",
        "              for i in range(0, len(df_dataset['INPUT_TEXT']))]"
      ],
      "metadata": {
        "id": "H_IA5Nm1vz2g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset['DOC2VEC'] = np.array(X_doc2vec).tolist()\n",
        "df_dataset.to_csv(DATASET_D2V_PATH)"
      ],
      "metadata": {
        "id": "TAlz7CrBEAUS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# load the model\n",
        "model = Word2Vec.load(W2V_MODEL_PATH)\n",
        "\n",
        "# now create a vector of word2vec embeddings for each discharge summary\n",
        "X_word2vec = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  # ignore words in not vocabulary\n",
        "  text = df_dataset[\"INPUT_TEXT\"][idx]\n",
        "  word_emb = [model.wv[w] for w in text if w in model.wv]\n",
        "  X_word2vec.append(word_emb)"
      ],
      "metadata": {
        "id": "L05N6L2f9E8w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 50 unique ICD codes.\n",
        "top_icd_codes = [codes for codes in df_dataset['ICD9_CODE']]\n",
        "top_icd_codes = np.unique([code for codes in top_icd_codes for code in codes])\n",
        "\n",
        "sorted_top_icd_codes = sorted(top_icd_codes)\n",
        "icd_code_to_idx = dict((k, v) for v, k in enumerate(sorted_top_icd_codes))\n",
        "\n",
        "multi_hot_ecoding_col = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  icd_codes = df_dataset.iloc[idx]['ICD9_CODE']\n",
        "  encoding = [0] * 50\n",
        "  for code in icd_codes:\n",
        "    encoding[icd_code_to_idx[code]] = 1    \n",
        "  multi_hot_ecoding_col.append(encoding)\n",
        "\n",
        "# new add a new column with multi-hot encoding.\n",
        "df_dataset['ICD9_CODE_ENCODED'] = multi_hot_ecoding_col\n",
        "\n",
        "# multi-hot encoding for ICD codes diagnosed.\n",
        "y = df_dataset['ICD9_CODE_ENCODED'].to_list()"
      ],
      "metadata": {
        "id": "deKr44cawezx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_word2vec))\n",
        "print(len(X_doc2vec))\n",
        "print(len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05VFq48T_7b2",
        "outputId": "8759d4aa-49de-4c87-aef8-f4d4d835f0c3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55988\n",
            "55988\n",
            "55988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets and Dataloaders"
      ],
      "metadata": {
        "id": "PeBZno_f-Usd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "q7u-eGRx-2XE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_dataset(dataset, vec_size):\n",
        "  seq_lengths = list()\n",
        "\n",
        "  for idx in range(len(dataset)):\n",
        "    seq_lengths.append(len(dataset[idx]))\n",
        "  max_seq_length = max(seq_lengths)\n",
        "\n",
        "  padded_dataset = torch.zeros([len(dataset), max_seq_length, vec_size], \n",
        "                               dtype=torch.float)\n",
        "  for i in range(len(dataset)):\n",
        "    for j in range(len(dataset[i])):\n",
        "      padded_dataset[i][j] = torch.FloatTensor(dataset[i][j])\n",
        "  \n",
        "  return padded_dataset"
      ],
      "metadata": {
        "id": "nWxMgdES-wg4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(data):\n",
        "  x_w2v, x_d2v, y_batch = zip(*data)\n",
        "  x_w2v = pad_dataset(x_w2v, W2V_EMB_SIZE)\n",
        "  x_d2v = torch.FloatTensor(x_d2v)\n",
        "  y_batch = torch.FloatTensor(y_batch)\n",
        "  # move to gpus\n",
        "  x_w2v = x_w2v.cuda() if torch.cuda.is_available() else x_w2v\n",
        "  x_d2v = x_d2v.cuda() if torch.cuda.is_available() else x_d2v\n",
        "  y_batch = y_batch.cuda() if torch.cuda.is_available() else y_batch\n",
        "  return (x_w2v, x_d2v), y_batch"
      ],
      "metadata": {
        "id": "E9fc5q6m-zVL"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, X_w2v, X_d2v, y):              \n",
        "    self.X_w2v = X_w2v\n",
        "    self.X_d2v = X_d2v\n",
        "    self.y = y\n",
        "    \n",
        "  def __len__(self):                \n",
        "    return len(self.y)\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    return self.X_w2v[index], self.X_d2v[index], self.y[index]\n",
        "\n",
        "dataset = CustomDataset(X_word2vec, X_doc2vec, y)\n",
        "split = int(len(dataset)*0.8)\n",
        "lengths = [split, len(dataset) - split]\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, lengths)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, \n",
        "                          batch_size=TRAINING_BATCH_SIZE, \n",
        "                          collate_fn=collate_fn)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, shuffle=True, \n",
        "                         batch_size=TRAINING_BATCH_SIZE, \n",
        "                         collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "hOa5r2Em-Ypb"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "yC6wO1jJA2-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(CNNModel, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 64, (5, 128), 1)\n",
        "    self.max_pool = torch.nn.MaxPool2d(4)\n",
        "    self.dropout = torch.nn.Dropout(0.75)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "  \n",
        "  def forward(self, X):\n",
        "    out = self.conv1(X)\n",
        "    # print(out.shape)\n",
        "    out = self.relu(out)\n",
        "    x_in = torch.squeeze(out, dim=3)\n",
        "    # print(x_in.shape)\n",
        "    out = self.max_pool(x_in)\n",
        "    out = self.dropout(out)\n",
        "    # print(out.shape)\n",
        "    out = torch.flatten(out, 1)\n",
        "    return out\n",
        "\n",
        "class DeepLabeler(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(DeepLabeler, self).__init__()\n",
        "    self.cnn = CNNModel()    \n",
        "    self.fc = nn.Linear(4112, 50)\n",
        "    self.dropout = nn.Dropout(0.75)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, X_w2vec, X_d2vec):\n",
        "    out1 = self.cnn(X_w2vec)\n",
        "    print(out1.shape)\n",
        "    print(X_d2vec.shape)\n",
        "    X_concat = torch.cat((out1, X_d2vec), 1)\n",
        "    out2 = self.sigmoid(self.fc(X_concat))\n",
        "    print(out2.shape)\n",
        "    return out2\n",
        "  \n",
        "  def get_name():\n",
        "    return \"deep-labeler\""
      ],
      "metadata": {
        "id": "GekrpFKWxB8v"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_sample = next(iter(train_loader))\n",
        "X_sample[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28zC-3C3K6wU",
        "outputId": "5063479c-cfa2-4ffb-a09b-9b2468184d22"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400, 1000, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_sample[0][1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho90S3f0SKNg",
        "outputId": "00eb62e5-842e-438f-d173-7e42b11ccff1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = DeepLabeler()\n",
        "x1_in = torch.unsqueeze(X_sample[0][0], dim=1)\n",
        "print(x1_in.shape)\n",
        "x2_in = X_sample[0][1]\n",
        "print(x2_in.shape)\n",
        "out = m1(x1_in, x2_in)\n",
        "out.shape\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zoG2jlZLklV",
        "outputId": "4b8e8196-324d-4260-aeff-1fc10b47fb5f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([400, 1, 1000, 128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400, 3984])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400, 50])\n",
            "tensor([[0.5598, 0.6411, 0.5223,  ..., 0.5178, 0.4665, 0.5179],\n",
            "        [0.4518, 0.4751, 0.4671,  ..., 0.5421, 0.4803, 0.5803],\n",
            "        [0.5321, 0.5355, 0.5016,  ..., 0.4799, 0.4733, 0.3935],\n",
            "        ...,\n",
            "        [0.4804, 0.4114, 0.4845,  ..., 0.5279, 0.4329, 0.5696],\n",
            "        [0.4938, 0.5693, 0.5384,  ..., 0.4730, 0.3922, 0.4981],\n",
            "        [0.4086, 0.5665, 0.4872,  ..., 0.3397, 0.4256, 0.5571]],\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "waC5QEuaA84C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "def get_model_file_name(modelname=\"model\"):\n",
        "  return \"/content/drive/My Drive/DLH Final Project/models/\" + modelname + \"-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")\n",
        "\n",
        "def get_stats_file_name(modelname=\"model\"):\n",
        "  return \"/content/drive/My Drive/DLH Final Project/stats/\" + modelname + \"-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")\n",
        "\n",
        "def get_results_file_name(modelname=\"model\"):\n",
        "  return \"/content/drive/My Drive/DLH Final Project/results/\" + modelname + \\\n",
        "                  \"-\" + datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")"
      ],
      "metadata": {
        "id": "v3jta40-C7xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "no_of_epocs = 100\n",
        "\n",
        "def train_model(model, loss, optimizer, train_loader):\n",
        "\n",
        "  main_memory_usage = list()\n",
        "  gpu_memory_usage = list()\n",
        "  gpu_time = list()\n",
        "  train_loss = list()\n",
        "\n",
        "  for e in range(no_of_epocs):\n",
        "    model.train()\n",
        "    epoc_train_loss = 0\n",
        "    main_memory_before = psutil.virtual_memory().used\n",
        "    gpu_memory_before = torch.cuda.memory_allocated()\n",
        "    start_time = time.time()\n",
        "\n",
        "    # iterate over data in mini batches.\n",
        "    for tup, y_batch in train_loader:    \n",
        "      model.zero_grad()\n",
        "      pred = model(tup)\n",
        "      l = loss(pred, y_batch)\n",
        "      l.backward()\n",
        "      optimizer.step()    \n",
        "      epoc_train_loss += l.item()\n",
        "      \n",
        "    # print epoc level training loss.\n",
        "    print(f\"epoc: {e}: Train Loss: {epoc_train_loss/len(train_loader)}\")\n",
        "    \n",
        "    # collect cpu and memory stats.\n",
        "    memory_used = psutil.virtual_memory().used\n",
        "    gpu_memory_used = torch.cuda.memory_allocated()\n",
        "    run_time = time.time() - start_time\n",
        "    print(f\"time: {run_time} memory_used: {memory_used} gpu_memory_used: {gpu_memory_used}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    train_loss.append(epoc_train_loss/len(train_loader))\n",
        "    main_memory_usage.append(memory_used)\n",
        "    gpu_memory_usage.append(gpu_memory_used)\n",
        "    gpu_time.append(run_time)\n",
        "    # end of one epoc\n",
        "\n",
        "  # save the model\n",
        "  torch.save(model.state_dict(), get_model_file_name(model.get_name()))\n",
        "  # print and collect stats.\n",
        "  print(psutil.virtual_memory())\n",
        "\n",
        "  stats = {\n",
        "      \"gpu_mem\": gpu_memory_usage,\n",
        "      \"main_mem\": main_memory_usage,\n",
        "      \"gpu_time\": gpu_time,\n",
        "      \"vmm_info\": psutil.virtual_memory()\n",
        "  }\n",
        "\n",
        "  with open(get_stats_file_name(model.get_name()), \"ab\") as sfile:\n",
        "    pickle.dump(stats, sfile)"
      ],
      "metadata": {
        "id": "cSOc8usuC9Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DeepLabeler()\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(f\"No of parameters to train: \\\n",
        "        {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "train_model(model, loss_fn, optim, train_loader)"
      ],
      "metadata": {
        "id": "4ChBSS43DTIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "rtLpiRHwA_jM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "  model.eval()\n",
        "  y_pred_all = list()\n",
        "  y_true_all = list()\n",
        "\n",
        "  for tup, y_batch in test_loader:\n",
        "    y_pred = model(tup)\n",
        "    y_pred = y_pred > 0.20 # TODO: remove hard coding\n",
        "    y_pred_all.extend(y_pred.detach().to('cpu').numpy())\n",
        "    y_true_all.extend(y_batch.detach().to('cpu').numpy())\n",
        "\n",
        "  y_true_all = np.array(y_true_all)\n",
        "  y_pred_all = np.array(y_pred_all)\n",
        "\n",
        "  # micro level metrics\n",
        "  p1, r1, f1, s1 = precision_recall_fscore_support(y_true_all, y_pred_all, \n",
        "                                                  average=\"micro\")\n",
        "  micro_auc = roc_auc_score(y_true_all, y_pred_all, average=\"micro\")\n",
        "  print(f\"Micro Averaging. Precision: {p1}, Recall: {r1}, F1 Score: {f1}, \\\n",
        "          AUC: {micro_auc}\")\n",
        "\n",
        "  # macro level metrics\n",
        "  p2, r2, f2, s2 = precision_recall_fscore_support(y_true_all, y_pred_all, \n",
        "                                                  average=\"macro\")\n",
        "  macro_auc = roc_auc_score(y_true_all, y_pred_all, average=\"macro\")\n",
        "  print(f\"Macro Averaging. Precision: {p2}, Recall: {r2}, F1 Score: {f2}, \\\n",
        "          AUC: {macro_auc}\")\n",
        "\n",
        "  results = {\n",
        "      \"micro\": [p1, r1, f1],\n",
        "      \"macro\": [p2, r2, f2]\n",
        "  }\n",
        "\n",
        "  with open(get_results_file_name(model.get_name()), \"ab\") as rfile:\n",
        "    pickle.dump(results, rfile)\n",
        "  \n",
        "  for idx in range(50):\n",
        "    p, r, f, _12 = precision_recall_fscore_support(y_true_all[:,idx], \n",
        "                                                 y_pred_all[:,idx], \n",
        "                                                 average='binary')\n",
        "    print(f\"p={p}, r={r}, f={f}\")"
      ],
      "metadata": {
        "id": "lEgWH_NqDD5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model is None:\n",
        "  print(\"load from disk\")\n",
        "  model = DeepLabeler()\n",
        "  if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    model.load_state_dict(torch.load(f\"{PROJECT_PATH}/models/\"))\n",
        "    evaluate_model(model, test_loader)\n",
        "else:\n",
        "  print(\"evaluating in-memory model\")\n",
        "  evaluate_model(model, train_loader)"
      ],
      "metadata": {
        "id": "pXDpBx8jDkNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}