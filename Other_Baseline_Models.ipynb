{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Other Baseline Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "authorship_tag": "ABX9TyPpOmwRLMOdyJ+GVjand4DP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amyth18/CS598-Deep-Learning-Final-Project/blob/main/Other_Baseline_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "In this notebook we provide the implementation for DeepLabeler model as proposed in the paper [Automated ICD-9 Coding via A Deep Learning Approach.](https://ieeexplore.ieee.org/document/8320340) by Min Li et al. The model makes disease prediction by using all of the clinical text (using Doc2Vec) as input to a Convolutional Neural Network. We use this model as one of baseline models to compare our main model implemented in [Main_Model.ipynb](https://github.com/amyth18/CS598-Deep-Learning-Final-Project/blob/main/Main_Model.ipynb)."
      ],
      "metadata": {
        "id": "pBUb6RByTug-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Requisites\n",
        "\n",
        "Before you can run this notebook you need to gain access to MIMIC III version 1.4 dataset from physionet.org, please refer to Pre-Requisites section in the Readme file in the GitHub repository for more details.\n",
        "\n",
        "For this notebook we specifically we need the `NOTEVENTS.csv` and `DIAGNOSES_ICD.csv` files from the MIMIC III dataset.\n",
        "\n",
        "We use Google Drive to store all our data including the original dataset, transformed/pre-processed dataset, trained models and evaluation results. Before you get started please create a top level folder in your Google Drive and update the project level env variable ```PROJECT_PATH``` in the **Intial Setup** section.\n",
        "\n",
        "Once the top level folder is created, please save the MIMIC III dataset (i.e the de-compressed csv files) in a folder called ```mimic3```. If you don't have space to save all the files, you can only save the `NOTEVENTS.csv` and `DIAGNOSES_ICD.csv`files.\n",
        "\n",
        "Also, in the same top level folder create the following folders where the notebook will save various results.\n",
        "1. ```models```\n",
        "2. ```results```\n",
        "3. ```stats```"
      ],
      "metadata": {
        "id": "8zQu4CbfVLcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ],
      "metadata": {
        "id": "-vFEFxSyVmFc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i_en9fHp43m"
      },
      "outputs": [],
      "source": [
        "! pip install gensim --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJNa7v3lsRoA",
        "outputId": "f054e08a-0afb-42d7-df88-fd35b40d116b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Yg41pDraqbIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_PATH = \"/content/drive/My Drive/DLH Final Project\"\n",
        "DATASET_PATH = f\"{PROJECT_PATH}/mimic3/df_dataset_full_text.csv\"\n",
        "DATASET_D2V_PATH = f\"{PROJECT_PATH}/mimic3/df_dataset_full_text_d2v.csv\"\n",
        "DOC2VEC_PATH = f\"{PROJECT_PATH}/models/doc2vec.model\"\n",
        "W2V_MODEL_PATH = f\"{PROJECT_PATH}/models/word2vec.model\"\n",
        "\n",
        "TRAINING_BATCH_SIZE = 400\n",
        "MAX_WORDS = 1000\n",
        "W2V_EMB_SIZE = 128"
      ],
      "metadata": {
        "id": "lGz7aVYrqvJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls \"/content/drive/My Drive/DLH Final Project/models\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F57y2QCLsIEq",
        "outputId": "3ca1743f-47cb-43d8-f843-ae1233f5e8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doc2vec.model\t\t\tmain-model-27-04-2022-19-11-16\n",
            "doc2vec.model.syn1neg.npy\ttf-idf-27-04-2022-16-29-54\n",
            "doc2vec.model.wv.vectors.npy\tword2vec-27-04-2022-17-47-59\n",
            "main-model-27-04-2022-15-40-59\tword2vec.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "PuUIA2ZgBHuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset = pd.read_csv(DATASET_PATH, converters={'INPUT_TEXT': eval, \n",
        "                                                   'ICD9_CODE': eval})"
      ],
      "metadata": {
        "id": "ivuKcLL6qYzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from os import path\n",
        "\n",
        "model = None\n",
        "\n",
        "if path.exists(DOC2VEC_PATH):\n",
        "  print(\"Loading doc2vec model from disk.\")\n",
        "  model = Doc2Vec.load(DOC2VEC_PATH)\n",
        "else:\n",
        "  print(\"Building doc2vec model.\")\n",
        "  docs = [TaggedDocument(doc, [i])\n",
        "          for i, doc in enumerate(df_dataset.INPUT_TEXT)]\n",
        "\n",
        "  model = Doc2Vec(vector_size=128, window=2, \n",
        "                  min_count=1, \n",
        "                  workers=8, \n",
        "                  epochs = 40)\n",
        "\n",
        "  model.build_vocab(docs)\n",
        "\n",
        "  model.train(docs, total_examples=model.corpus_count, \n",
        "              epochs=model.epochs)\n",
        "  model.save(DOC2VEC_PATH)"
      ],
      "metadata": {
        "id": "2z6DqEnOt08a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_doc2vec = [model.infer_vector(df_dataset['INPUT_TEXT'][i]) \n",
        "              for i in range(0, len(df_dataset['INPUT_TEXT']))]"
      ],
      "metadata": {
        "id": "H_IA5Nm1vz2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset['DOC2VEC'] = np.array(X_doc2vec).tolist()\n",
        "df_dataset.to_csv(DATASET_D2V_PATH)"
      ],
      "metadata": {
        "id": "TAlz7CrBEAUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "9reTI7ddGolP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset = pd.read_csv(DATASET_D2V_PATH, \n",
        "                         converters={'INPUT_TEXT': eval, \n",
        "                                     'ICD9_CODE': eval,\n",
        "                                     'DOC2VEC': eval})"
      ],
      "metadata": {
        "id": "Eb2F4G2eG20U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# load the model\n",
        "model = Word2Vec.load(W2V_MODEL_PATH)\n",
        "\n",
        "# now create a vector of word2vec embeddings for each discharge summary\n",
        "X_word2vec = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  # ignore words in not vocabulary\n",
        "  text = df_dataset[\"INPUT_TEXT\"][idx]\n",
        "  word_emb = [model.wv[w] for w in text if w in model.wv]\n",
        "  X_word2vec.append(word_emb)"
      ],
      "metadata": {
        "id": "L05N6L2f9E8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 50 unique ICD codes.\n",
        "top_icd_codes = [codes for codes in df_dataset['ICD9_CODE']]\n",
        "top_icd_codes = np.unique([code for codes in top_icd_codes for code in codes])\n",
        "\n",
        "sorted_top_icd_codes = sorted(top_icd_codes)\n",
        "icd_code_to_idx = dict((k, v) for v, k in enumerate(sorted_top_icd_codes))\n",
        "\n",
        "multi_hot_ecoding_col = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  icd_codes = df_dataset.iloc[idx]['ICD9_CODE']\n",
        "  encoding = [0] * 50\n",
        "  for code in icd_codes:\n",
        "    encoding[icd_code_to_idx[code]] = 1    \n",
        "  multi_hot_ecoding_col.append(encoding)\n",
        "\n",
        "# new add a new column with multi-hot encoding.\n",
        "df_dataset['ICD9_CODE_ENCODED'] = multi_hot_ecoding_col\n",
        "\n",
        "# multi-hot encoding for ICD codes diagnosed.\n",
        "y = df_dataset['ICD9_CODE_ENCODED'].to_list()"
      ],
      "metadata": {
        "id": "deKr44cawezx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_doc2vec = df_dataset[\"DOC2VEC\"]"
      ],
      "metadata": {
        "id": "LY8vi4oQXVld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_word2vec))\n",
        "print(len(X_doc2vec))\n",
        "print(len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05VFq48T_7b2",
        "outputId": "2bb14870-d35d-4479-b7a3-3c2efd275596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55988\n",
            "55988\n",
            "55988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets and Dataloaders"
      ],
      "metadata": {
        "id": "PeBZno_f-Usd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "q7u-eGRx-2XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_dataset(dataset, vec_size):\n",
        "  seq_lengths = list()\n",
        "\n",
        "  # for idx in range(len(dataset)):\n",
        "  #   seq_lengths.append(len(dataset[idx]))\n",
        "  # max_seq_length = max(seq_lengths)\n",
        "\n",
        "  padded_dataset = torch.zeros([len(dataset), MAX_WORDS, vec_size], \n",
        "                               dtype=torch.float)\n",
        "  for i in range(len(dataset)):\n",
        "    for j in range(len(dataset[i])):\n",
        "      padded_dataset[i][j] = torch.FloatTensor(dataset[i][j])\n",
        "  \n",
        "  return padded_dataset"
      ],
      "metadata": {
        "id": "nWxMgdES-wg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def collate_fn(data):\n",
        "  x_w2v, x_d2v, y_batch = zip(*data)  \n",
        "  x_w2v = pad_dataset(x_w2v, W2V_EMB_SIZE)  \n",
        "  x_d2v = torch.FloatTensor(x_d2v)\n",
        "  y_batch = torch.FloatTensor(y_batch)\n",
        "  # move to gpus\n",
        "  x_w2v = x_w2v.cuda() if torch.cuda.is_available() else x_w2v\n",
        "  x_d2v = x_d2v.cuda() if torch.cuda.is_available() else x_d2v\n",
        "  y_batch = y_batch.cuda() if torch.cuda.is_available() else y_batch\n",
        "  return (x_w2v, x_d2v), y_batch"
      ],
      "metadata": {
        "id": "E9fc5q6m-zVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, X_w2v, X_d2v, y):              \n",
        "    self.X_w2v = X_w2v\n",
        "    self.X_d2v = X_d2v\n",
        "    self.y = y\n",
        "    \n",
        "  def __len__(self):                \n",
        "    return len(self.y)\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    return self.X_w2v[index], self.X_d2v[index], self.y[index]\n",
        "\n",
        "dataset = CustomDataset(X_word2vec, X_doc2vec, y)\n",
        "split = int(len(dataset)*0.8)\n",
        "lengths = [split, len(dataset) - split]\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, lengths)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, \n",
        "                          batch_size=TRAINING_BATCH_SIZE, \n",
        "                          collate_fn=collate_fn)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, shuffle=True, \n",
        "                         batch_size=TRAINING_BATCH_SIZE, \n",
        "                         collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "hOa5r2Em-Ypb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "yC6wO1jJA2-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(CNNModel, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 64, (5, 128), 1)\n",
        "    self.max_pool = torch.nn.MaxPool2d(4)\n",
        "    self.dropout = torch.nn.Dropout(0.75)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "  \n",
        "  def forward(self, X):\n",
        "    out = self.conv1(X)\n",
        "    # print(out.shape)\n",
        "    out = self.relu(out)\n",
        "    x_in = torch.squeeze(out, dim=3)\n",
        "    # print(x_in.shape)\n",
        "    out = self.max_pool(x_in)\n",
        "    out = self.dropout(out)\n",
        "    # print(out.shape)\n",
        "    out = torch.flatten(out, 1)\n",
        "    return out\n",
        "\n",
        "class DeepLabeler(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(DeepLabeler, self).__init__()\n",
        "    self.cnn = CNNModel()    \n",
        "    self.fc = nn.Linear(4112, 50)\n",
        "    self.dropout = nn.Dropout(0.75)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, X_w2vec, X_d2vec):\n",
        "    out1 = self.cnn(X_w2vec)\n",
        "    # print(out1.shape)\n",
        "    # print(X_d2vec.shape)\n",
        "    X_concat = torch.cat((out1, X_d2vec), 1)\n",
        "    out2 = self.sigmoid(self.fc(X_concat))\n",
        "    # print(out2.shape)\n",
        "    return out2\n",
        "  \n",
        "  def get_name():\n",
        "    return \"deep-labeler\""
      ],
      "metadata": {
        "id": "GekrpFKWxB8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "waC5QEuaA84C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "def get_model_file_name(modelname=\"model\"):\n",
        "  return \"/content/drive/My Drive/DLH Final Project/models/\" + modelname + \"-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")\n",
        "\n",
        "def get_stats_file_name(modelname=\"model\"):\n",
        "  return \"/content/drive/My Drive/DLH Final Project/stats/\" + modelname + \"-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")\n",
        "\n",
        "def get_results_file_name(modelname=\"model\"):\n",
        "  return \"/content/drive/My Drive/DLH Final Project/results/\" + modelname + \\\n",
        "                  \"-\" + datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")"
      ],
      "metadata": {
        "id": "v3jta40-C7xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "no_of_epocs = 100\n",
        "\n",
        "def train_model(model, loss, optimizer, train_loader):\n",
        "\n",
        "  main_memory_usage = list()\n",
        "  gpu_memory_usage = list()\n",
        "  gpu_time = list()\n",
        "  train_loss = list()\n",
        "\n",
        "  for e in range(no_of_epocs):\n",
        "    model.train()\n",
        "    epoc_train_loss = 0\n",
        "    main_memory_before = psutil.virtual_memory().used\n",
        "    gpu_memory_before = torch.cuda.memory_allocated()\n",
        "    start_time = time.time()\n",
        "\n",
        "    # iterate over data in mini batches.\n",
        "    for tup, y_batch in train_loader:\n",
        "      X_w2v, X_d2v = tup\n",
        "      X_w2v = torch.unsqueeze(X_w2v, dim=1)\n",
        "      model.zero_grad()\n",
        "      pred = model(X_w2v, X_d2v)\n",
        "      l = loss(pred, y_batch)\n",
        "      l.backward()\n",
        "      optimizer.step()    \n",
        "      epoc_train_loss += l.item()\n",
        "      \n",
        "    # print epoc level training loss.\n",
        "    print(f\"epoc: {e}: Train Loss: {epoc_train_loss/len(train_loader)}\")\n",
        "    \n",
        "    # collect cpu and memory stats.\n",
        "    memory_used = psutil.virtual_memory().used\n",
        "    gpu_memory_used = torch.cuda.memory_allocated()\n",
        "    run_time = time.time() - start_time\n",
        "    print(f\"time: {run_time} memory_used: {memory_used} gpu_memory_used: {gpu_memory_used}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    train_loss.append(epoc_train_loss/len(train_loader))\n",
        "    main_memory_usage.append(memory_used)\n",
        "    gpu_memory_usage.append(gpu_memory_used)\n",
        "    gpu_time.append(run_time)\n",
        "    # end of one epoc\n",
        "\n",
        "  # save the model\n",
        "  torch.save(model.state_dict(), get_model_file_name(model.get_name()))\n",
        "  # print and collect stats.\n",
        "  print(psutil.virtual_memory())\n",
        "\n",
        "  stats = {\n",
        "      \"gpu_mem\": gpu_memory_usage,\n",
        "      \"main_mem\": main_memory_usage,\n",
        "      \"gpu_time\": gpu_time,\n",
        "      \"vmm_info\": psutil.virtual_memory()\n",
        "  }\n",
        "\n",
        "  with open(get_stats_file_name(model.get_name()), \"ab\") as sfile:\n",
        "    pickle.dump(stats, sfile)"
      ],
      "metadata": {
        "id": "cSOc8usuC9Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DeepLabeler()\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(f\"No of parameters to train: \\\n",
        "        {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "train_model(model, loss_fn, optim, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4ChBSS43DTIK",
        "outputId": "2223d7d7-7c1f-4143-d1fd-2be9307fdefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of parameters to train:         246674\n",
            "epoc: 0: Train Loss: 0.26725409446018084\n",
            "time: 392.7763228416443 memory_used: 10455932928 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 1: Train Loss: 0.22767333313822746\n",
            "time: 398.54994797706604 memory_used: 10453786624 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 2: Train Loss: 0.2204462287149259\n",
            "time: 396.1982464790344 memory_used: 10454323200 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 3: Train Loss: 0.21659478106136834\n",
            "time: 400.37121987342834 memory_used: 10454585344 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 4: Train Loss: 0.2142102364450693\n",
            "time: 402.3953001499176 memory_used: 10456240128 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 5: Train Loss: 0.2124074496594923\n",
            "time: 406.72699904441833 memory_used: 9789870080 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 6: Train Loss: 0.211052455141076\n",
            "time: 403.66787552833557 memory_used: 9788055552 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 7: Train Loss: 0.20988512970507145\n",
            "time: 403.0095522403717 memory_used: 9789186048 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 8: Train Loss: 0.20883436421198504\n",
            "time: 403.71639680862427 memory_used: 9790021632 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 9: Train Loss: 0.2079145023599267\n",
            "time: 396.64419507980347 memory_used: 9789124608 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 10: Train Loss: 0.2071220889421446\n",
            "time: 394.01008200645447 memory_used: 9789345792 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 11: Train Loss: 0.2064191084355116\n",
            "time: 402.2005660533905 memory_used: 9789255680 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 12: Train Loss: 0.20561125595122576\n",
            "time: 402.5058825016022 memory_used: 9792241664 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 13: Train Loss: 0.2050696544881378\n",
            "time: 404.74243545532227 memory_used: 9792212992 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 14: Train Loss: 0.20455738569476775\n",
            "time: 399.88096714019775 memory_used: 9789403136 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 15: Train Loss: 0.2039572885259986\n",
            "time: 400.371595621109 memory_used: 9792438272 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 16: Train Loss: 0.2037158426163452\n",
            "time: 400.35485553741455 memory_used: 9791819776 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 17: Train Loss: 0.2031447874116046\n",
            "time: 406.025013923645 memory_used: 9792659456 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 18: Train Loss: 0.20268864344273294\n",
            "time: 402.5065348148346 memory_used: 9793597440 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 19: Train Loss: 0.20220025296189956\n",
            "time: 406.4698781967163 memory_used: 9792339968 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 20: Train Loss: 0.20172748980777605\n",
            "time: 401.4585385322571 memory_used: 9792016384 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 21: Train Loss: 0.2015624621084758\n",
            "time: 405.2650890350342 memory_used: 9793839104 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 22: Train Loss: 0.20104475465736218\n",
            "time: 400.3861367702484 memory_used: 9793671168 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 23: Train Loss: 0.20087894278445415\n",
            "time: 407.1938850879669 memory_used: 9794322432 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 24: Train Loss: 0.20050464051642589\n",
            "time: 405.84429907798767 memory_used: 9792913408 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 25: Train Loss: 0.20041969045996666\n",
            "time: 399.94465613365173 memory_used: 9793859584 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 26: Train Loss: 0.20000982351068938\n",
            "time: 405.398921251297 memory_used: 9795600384 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 27: Train Loss: 0.19965104585779564\n",
            "time: 406.90077209472656 memory_used: 9795158016 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 28: Train Loss: 0.19930004674409116\n",
            "time: 401.0535137653351 memory_used: 9795080192 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 29: Train Loss: 0.19910984153726272\n",
            "time: 406.6641843318939 memory_used: 9795694592 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 30: Train Loss: 0.19873603087450778\n",
            "time: 405.11447930336 memory_used: 9796669440 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 31: Train Loss: 0.19838558230549097\n",
            "time: 420.0742747783661 memory_used: 9798774784 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 32: Train Loss: 0.19831025613737957\n",
            "time: 396.9037735462189 memory_used: 9796915200 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 33: Train Loss: 0.1981200800676431\n",
            "time: 410.8653018474579 memory_used: 9795973120 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 34: Train Loss: 0.19794621185532638\n",
            "time: 404.7491409778595 memory_used: 9795436544 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 35: Train Loss: 0.19770261498966388\n",
            "time: 405.78666377067566 memory_used: 9797066752 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 36: Train Loss: 0.19744869068797147\n",
            "time: 399.4867248535156 memory_used: 9797996544 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 37: Train Loss: 0.19707834547651665\n",
            "time: 407.1320390701294 memory_used: 9796386816 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 38: Train Loss: 0.19706314389726945\n",
            "time: 402.4015963077545 memory_used: 9798131712 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 39: Train Loss: 0.19706368938620603\n",
            "time: 406.38455080986023 memory_used: 9797001216 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 40: Train Loss: 0.1966301447578839\n",
            "time: 405.14396047592163 memory_used: 9797689344 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 41: Train Loss: 0.1964794180489012\n",
            "time: 402.9786367416382 memory_used: 9797791744 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 42: Train Loss: 0.1964496142630066\n",
            "time: 404.085022687912 memory_used: 9797443584 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 43: Train Loss: 0.19623822106846742\n",
            "time: 403.9621820449829 memory_used: 9799680000 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 44: Train Loss: 0.19579821319452353\n",
            "time: 406.97496724128723 memory_used: 9798582272 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 45: Train Loss: 0.19542887301317283\n",
            "time: 405.9609317779541 memory_used: 9800413184 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 46: Train Loss: 0.19567227975598403\n",
            "time: 406.0501539707184 memory_used: 9799643136 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 47: Train Loss: 0.19562323750661953\n",
            "time: 401.98568749427795 memory_used: 9800237056 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 48: Train Loss: 0.1950214317600642\n",
            "time: 414.69475769996643 memory_used: 9801064448 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 49: Train Loss: 0.19505046135080711\n",
            "time: 402.2829215526581 memory_used: 9801039872 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 50: Train Loss: 0.19490085821598768\n",
            "time: 411.5292429924011 memory_used: 9800577024 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 51: Train Loss: 0.19468000823897974\n",
            "time: 398.540735244751 memory_used: 9799770112 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 52: Train Loss: 0.19453686821673596\n",
            "time: 407.49531507492065 memory_used: 9799815168 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 53: Train Loss: 0.1943134515147124\n",
            "time: 402.18224906921387 memory_used: 9801469952 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 54: Train Loss: 0.19410277783338512\n",
            "time: 404.30763006210327 memory_used: 9801285632 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 55: Train Loss: 0.19374083993690355\n",
            "time: 403.1074674129486 memory_used: 9800065024 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 56: Train Loss: 0.19398567865469626\n",
            "time: 396.7557146549225 memory_used: 9800794112 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 57: Train Loss: 0.19373441474246128\n",
            "time: 405.6315495967865 memory_used: 9802240000 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 58: Train Loss: 0.19356393281902587\n",
            "time: 403.5652565956116 memory_used: 9802276864 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 59: Train Loss: 0.1935125126370362\n",
            "time: 392.2061483860016 memory_used: 9802551296 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 60: Train Loss: 0.19367304790232862\n",
            "time: 403.5632667541504 memory_used: 9803309056 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 61: Train Loss: 0.19326641942773545\n",
            "time: 403.156414270401 memory_used: 9800302592 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 62: Train Loss: 0.19281463511288166\n",
            "time: 396.1934220790863 memory_used: 9801728000 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 63: Train Loss: 0.19322284776717424\n",
            "time: 389.02744603157043 memory_used: 9800355840 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 64: Train Loss: 0.19299594845090592\n",
            "time: 398.24449706077576 memory_used: 9802166272 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 65: Train Loss: 0.19297688041946717\n",
            "time: 384.17811608314514 memory_used: 9802121216 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 66: Train Loss: 0.19274574957255805\n",
            "time: 387.7852370738983 memory_used: 9802829824 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 67: Train Loss: 0.1926105690321752\n",
            "time: 390.4627664089203 memory_used: 9802608640 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 68: Train Loss: 0.19269582855382136\n",
            "time: 392.52393221855164 memory_used: 9802940416 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 69: Train Loss: 0.1921968265835728\n",
            "time: 395.24814915657043 memory_used: 9802711040 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 70: Train Loss: 0.19216674752533436\n",
            "time: 395.86457085609436 memory_used: 9801940992 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 71: Train Loss: 0.19231083004602365\n",
            "time: 401.16713881492615 memory_used: 9802657792 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 72: Train Loss: 0.19214889952646835\n",
            "time: 395.16691970825195 memory_used: 9802153984 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 73: Train Loss: 0.19193186398063386\n",
            "time: 394.79705476760864 memory_used: 9803780096 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 74: Train Loss: 0.19185984799904482\n",
            "time: 391.5905168056488 memory_used: 9803763712 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 75: Train Loss: 0.19188945873507432\n",
            "time: 396.4092073440552 memory_used: 9802514432 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 76: Train Loss: 0.19161898735910654\n",
            "time: 411.07134318351746 memory_used: 9805062144 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 77: Train Loss: 0.19162262776600464\n",
            "time: 407.6578221321106 memory_used: 9803698176 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 78: Train Loss: 0.1915938455079283\n",
            "time: 406.1823856830597 memory_used: 9805058048 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 79: Train Loss: 0.19144013736929213\n",
            "time: 411.7418920993805 memory_used: 9806123008 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 80: Train Loss: 0.1915224830486945\n",
            "time: 409.43480253219604 memory_used: 9803198464 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 81: Train Loss: 0.1914433492347598\n",
            "time: 408.87422347068787 memory_used: 9804492800 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 82: Train Loss: 0.1911146156489849\n",
            "time: 415.3989579677582 memory_used: 9805025280 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 83: Train Loss: 0.1912806394643017\n",
            "time: 408.1711721420288 memory_used: 9804496896 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 84: Train Loss: 0.19125507612313544\n",
            "time: 406.9194507598877 memory_used: 9804898304 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 85: Train Loss: 0.19116604434592382\n",
            "time: 403.9108769893646 memory_used: 9804771328 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 86: Train Loss: 0.19101158542824642\n",
            "time: 407.931236743927 memory_used: 9804316672 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 87: Train Loss: 0.19098517671227455\n",
            "time: 408.29391264915466 memory_used: 9804177408 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 88: Train Loss: 0.19077255031360046\n",
            "time: 404.8183362483978 memory_used: 9805307904 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 89: Train Loss: 0.1907768878819687\n",
            "time: 404.6658158302307 memory_used: 9805451264 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 90: Train Loss: 0.19069991340594633\n",
            "time: 409.4904294013977 memory_used: 9805291520 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 91: Train Loss: 0.190674529943083\n",
            "time: 399.89571738243103 memory_used: 9805688832 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 92: Train Loss: 0.1909611209162644\n",
            "time: 405.18338108062744 memory_used: 9804943360 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 93: Train Loss: 0.1904559519940189\n",
            "time: 411.0038158893585 memory_used: 9807142912 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 94: Train Loss: 0.19048017689159938\n",
            "time: 404.00247025489807 memory_used: 9805697024 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 95: Train Loss: 0.190332277278815\n",
            "time: 404.89860439300537 memory_used: 9805844480 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 96: Train Loss: 0.1904057144586529\n",
            "time: 408.6028435230255 memory_used: 9806151680 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 97: Train Loss: 0.1904769619660718\n",
            "time: 408.1763184070587 memory_used: 9806295040 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 98: Train Loss: 0.19016631253595864\n",
            "time: 405.3035628795624 memory_used: 9806680064 gpu_memory_used: 833817600\n",
            "\n",
            "\n",
            "epoc: 99: Train Loss: 0.19009960469390666\n",
            "time: 403.34718680381775 memory_used: 9806532608 gpu_memory_used: 833817600\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-bd4a02632618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No of parameters to train:         {sum(p.numel() for p in model.parameters() if p.requires_grad)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-687d4cd2776d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, loss, optimizer, train_loader)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;31m# save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model_file_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0;31m# print and collect stats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get_name() takes 0 positional arguments but 1 was given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(get_stats_file_name(\"deep-labeler\"), \"ab\") as sfile:\n",
        "    pickle.dump(model, sfile)"
      ],
      "metadata": {
        "id": "lSemGIpA22aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "rtLpiRHwA_jM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "  model.eval()\n",
        "  y_pred_all = list()\n",
        "  y_true_all = list()\n",
        "\n",
        "  for tup, y_batch in test_loader:\n",
        "    X_w2v, X_d2v = tup\n",
        "    X_w2v = torch.unsqueeze(X_w2v, dim=1)\n",
        "    y_pred = model(X_w2v, X_d2v)\n",
        "    y_pred = y_pred > 0.20 # TODO: remove hard coding\n",
        "    y_pred_all.extend(y_pred.detach().to('cpu').numpy())\n",
        "    y_true_all.extend(y_batch.detach().to('cpu').numpy())\n",
        "\n",
        "  y_true_all = np.array(y_true_all)\n",
        "  y_pred_all = np.array(y_pred_all)\n",
        "\n",
        "  # micro level metrics\n",
        "  p1, r1, f1, s1 = precision_recall_fscore_support(y_true_all, y_pred_all, \n",
        "                                                  average=\"micro\")\n",
        "  micro_auc = roc_auc_score(y_true_all, y_pred_all, average=\"micro\")\n",
        "  print(f\"Micro Averaging. Precision: {p1}, Recall: {r1}, F1 Score: {f1}, \\\n",
        "          AUC: {micro_auc}\")\n",
        "\n",
        "  # macro level metrics\n",
        "  p2, r2, f2, s2 = precision_recall_fscore_support(y_true_all, y_pred_all, \n",
        "                                                  average=\"macro\")\n",
        "  macro_auc = roc_auc_score(y_true_all, y_pred_all, average=\"macro\")\n",
        "  print(f\"Macro Averaging. Precision: {p2}, Recall: {r2}, F1 Score: {f2}, \\\n",
        "          AUC: {macro_auc}\")\n",
        "\n",
        "  results = {\n",
        "      \"micro\": [p1, r1, f1],\n",
        "      \"macro\": [p2, r2, f2]\n",
        "  }\n",
        "\n",
        "  with open(get_results_file_name(\"deep-labeler\"), \"ab\") as rfile:\n",
        "    pickle.dump(results, rfile)\n",
        "  \n",
        "  for idx in range(50):\n",
        "    p, r, f, _12 = precision_recall_fscore_support(y_true_all[:,idx], \n",
        "                                                 y_pred_all[:,idx], \n",
        "                                                 average='binary')\n",
        "    print(f\"p={p}, r={r}, f={f}\")"
      ],
      "metadata": {
        "id": "lEgWH_NqDD5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model is None:\n",
        "  print(\"load from disk\")\n",
        "  model = DeepLabeler()\n",
        "  if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    model.load_state_dict(torch.load(f\"{PROJECT_PATH}/models/\"))\n",
        "    evaluate_model(model, test_loader)\n",
        "else:\n",
        "  print(\"evaluating in-memory model\")\n",
        "  evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXDpBx8jDkNs",
        "outputId": "864e7354-c51a-40ba-f047-8d2c41daa07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating in-memory model\n",
            "Micro Averaging. Precision: 0.43531539678950937, Recall: 0.5684117299744145, F1 Score: 0.49303913618710254,           AUC: 0.7474107992817327\n",
            "Macro Averaging. Precision: 0.39562850169915237, Recall: 0.4724516202766275, F1 Score: 0.4190941059846913,           AUC: 0.6954960423444898\n",
            "p=0.37510729613733906, r=0.5421836228287841, f=0.443429731100964\n",
            "p=0.5836431226765799, r=0.5804066543438078, f=0.5820203892493049\n",
            "p=0.36137366099558915, r=0.5758032128514057, f=0.44405729771583435\n",
            "p=0.30420280186791193, r=0.3627684964200477, f=0.3309143686502177\n",
            "p=0.38059047062262497, r=0.6899841017488076, f=0.4905802562170309\n",
            "p=0.28212290502793297, r=0.2069672131147541, f=0.23877068557919623\n",
            "p=0.23865877712031558, r=0.18113772455089822, f=0.20595744680851066\n",
            "p=0.2871287128712871, r=0.3228744939271255, f=0.3039542639352072\n",
            "p=0.3746630727762803, r=0.29324894514767935, f=0.3289940828402367\n",
            "p=0.47126436781609193, r=0.5705765407554672, f=0.5161870503597122\n",
            "p=0.2181571815718157, r=0.13690476190476192, f=0.16823406478578895\n",
            "p=0.2783018867924528, r=0.17302052785923755, f=0.21338155515370705\n",
            "p=0.29739776951672864, r=0.22191400832177532, f=0.2541699761715648\n",
            "p=0.24956063268892795, r=0.1977715877437326, f=0.2206682206682207\n",
            "p=0.378125, r=0.2439516129032258, f=0.2965686274509804\n",
            "p=0.4975398313027179, r=0.9516020613936814, f=0.6534348796061236\n",
            "p=0.3594306049822064, r=0.4105691056910569, f=0.38330170777988615\n",
            "p=0.52, r=0.6179577464788732, f=0.5647626709573612\n",
            "p=0.3212121212121212, r=0.4602026049204052, f=0.3783462224866151\n",
            "p=0.2629032258064516, r=0.21391076115485563, f=0.23589001447178\n",
            "p=0.6016837674296238, r=0.8223660553757641, f=0.6949255545426922\n",
            "p=0.375, r=0.3140625, f=0.34183673469387754\n",
            "p=0.6182212581344902, r=0.504424778761062, f=0.5555555555555556\n",
            "p=0.5914074737077646, r=0.9139004149377593, f=0.7181089525879635\n",
            "p=0.2357142857142857, r=0.060218978102189784, f=0.09593023255813954\n",
            "p=0.5013736263736264, r=0.8522348232154769, f=0.6313318507536447\n",
            "p=0.29004854368932037, r=0.43933823529411764, f=0.34941520467836257\n",
            "p=0.23972602739726026, r=0.07918552036199095, f=0.11904761904761903\n",
            "p=0.23819978046103182, r=0.2265135699373695, f=0.23220973782771537\n",
            "p=0.4688995215311005, r=0.4661117717003567, f=0.46750149075730474\n",
            "p=0.23529411764705882, r=0.20880913539967375, f=0.2212618841832325\n",
            "p=0.4310405643738977, r=0.7474006116207951, f=0.5467561521252796\n",
            "p=0.30115361262902246, r=0.36072727272727273, f=0.32825943084050296\n",
            "p=0.29867674858223064, r=0.3191919191919192, f=0.30859375\n",
            "p=0.42005988023952096, r=0.7018509254627313, f=0.5255665855029032\n",
            "p=0.33825338253382536, r=0.36764705882352944, f=0.3523382447149263\n",
            "p=0.4211494252873563, r=0.6010498687664042, f=0.49526899161935656\n",
            "p=0.6996951219512195, r=0.936734693877551, f=0.8010471204188482\n",
            "p=0.4270986745213549, r=0.5291970802919708, f=0.4726976365118174\n",
            "p=0.44516653127538586, r=0.6773794808405439, f=0.5372549019607843\n",
            "p=0.34450651769087526, r=0.33575317604355714, f=0.34007352941176466\n",
            "p=0.5968882602545968, r=0.9440715883668904, f=0.731369150779896\n",
            "p=0.2237442922374429, r=0.08448275862068966, f=0.12265331664580725\n",
            "p=0.6671177266576455, r=0.9685658153241651, f=0.7900641025641025\n",
            "p=0.7524271844660194, r=0.8378378378378378, f=0.7928388746803069\n",
            "p=0.6530172413793104, r=0.9409937888198758, f=0.7709923664122138\n",
            "p=0.34615384615384615, r=0.3204334365325077, f=0.33279742765273307\n",
            "p=0.30326295585412666, r=0.26421404682274247, f=0.2823949955317247\n",
            "p=0.34297872340425534, r=0.5114213197969543, f=0.41059602649006627\n",
            "p=0.3320825515947467, r=0.33270676691729323, f=0.3323943661971831\n"
          ]
        }
      ]
    }
  ]
}