{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amyth18/CS598-Deep-Learning-Final-Project/blob/main/CS598_Deep_Learning_For_Healthcare_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gensim --upgrade\n",
        "! pip install psutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHtTRNjY6fjL",
        "outputId": "85c70925-23a8-4636-f7a7-aeb1a1d9fbca"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "yZM4PBDMRCc_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFlP8qR9EAEW",
        "outputId": "581573d9-dc4a-4482-d480-731d4d1f1786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZrO8Ao004k3"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcubO8rgEqXh",
        "outputId": "c59fac88-ba1d-4f00-b0d6-d6f43ac8b954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "# read data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/DLH Final Project/mimic3/NOTEEVENTS.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASN9TUHWgnz7"
      },
      "source": [
        "# Data Preprocessing\n",
        "Need to focus on 2 tables\n",
        "1. NOTESEVENTS.csv\n",
        "2. DIAGNOSES_ICD.csv\n",
        "\n",
        "Join tables by <subject_id, hadm_id>\n",
        "\n",
        "Construct 2 datasets from \"TEXT\" field in NOTESEVENTS.csv for each <subject_id, hadm_id> pair (i.e discharge summary for that admission.)\n",
        "\n",
        "X1, y and X2, y\n",
        "x1 = sequence of vectors from word2vec \n",
        "x2 = sequence of vectors from tf-idf\n",
        "y = list of icd codes for <subject_id, hadm_id> i.e. diagnosis maded in ICU admission.\n",
        "\n",
        "Need to focus on 50 and 100 most commonly diagnosed diseases.\n",
        "\n",
        "Use NLTK + MetaMap to extract only the symptom related entities (how to use MetaMap is unknown atm.)\n",
        "\n",
        "Filter out sections in discharge summaries that are related to symptoms only, ignore others to speed up things.\n",
        "\n",
        "Negative filters (e.g. \"no sign of breath problem\").\n",
        "\n",
        "Generate Word2Vec embeddings (currently using Gensim) using \"TEXT\".\n",
        "\n",
        "Generate TF-IDF vector for each symptom entity.\n",
        "\n",
        "Generate multi-hot encoding for y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Routines For Data Processing"
      ],
      "metadata": {
        "id": "kxdU3qT1k3m7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TV7TblwfIxta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "009aa16d-03d9-49ca-8dc4-b7ca329d0c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "eng_stop_words =  stopwords.words('english')\n",
        "\n",
        "class MySentences(object):\n",
        "    def __init__(self, dframe):\n",
        "        self.dframe = dframe\n",
        "    \n",
        "    # TODO: Keeping only alpha numeric characters and spaces for now.\n",
        "    # need to make this better. Find some good libraries.\n",
        "    def sanitize_text(self, text):\n",
        "      test = text.strip()\n",
        "      text = re.sub(r'\\s\\s+', ' ', text)\n",
        "      text = re.sub(r'[^a-zA-z0-9\\/\\.\\?\\!\\s;,\\'\\-]', '', text)\n",
        "      text = re.sub(r'[\\.\\-\\/\\?\\!;,]', ' ', text)\n",
        "      text = re.sub(r'[\\[\\]]', '', text)\n",
        "      return text\n",
        "\n",
        "    # TODO: adding some basic checks again need to make it better.\n",
        "    def sanitize_words(self, sentence):\n",
        "      return [w for w in sentence if w not in eng_stop_words and not w.isdigit()]\n",
        "\n",
        "    def __iter__(self):\n",
        "        for idx in range(len(self.dframe)):\n",
        "          text = self.sanitize_text(self.dframe[\"TEXT\"][idx])\n",
        "          yield self.sanitize_words(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_dataset(dataset):\n",
        "  seq_lengths = list()\n",
        "\n",
        "  for idx in range(len(dataset)):\n",
        "    seq_lengths.append(len(dataset[idx]))\n",
        "  max_seq_length = max(seq_lengths)\n",
        "\n",
        "  padded_dataset = torch.zeros([len(dataset), max_seq_length, len(dataset[0][0])], \n",
        "                               dtype=torch.float)\n",
        "  for i in range(len(dataset)):\n",
        "    for j in range(len(dataset[i])):\n",
        "      padded_dataset[i][j] = torch.FloatTensor(dataset[i][j])\n",
        "  \n",
        "  return padded_dataset"
      ],
      "metadata": {
        "id": "81XPts3oIlGR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "def get_model_file_name():\n",
        "  return \"/content/drive/My Drive/DLH Final Project/models/model-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")\n",
        "\n",
        "def get_stats_file_name():\n",
        "  return \"/content/drive/My Drive/DLH Final Project/stats/stats-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")\n",
        "\n",
        "def get_results_file_name():\n",
        "  return \"/content/drive/My Drive/DLH Final Project/stats/results-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")"
      ],
      "metadata": {
        "id": "pZ5obtEaX68T"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Filtering and Tranformation"
      ],
      "metadata": {
        "id": "n1xDk_pMlBPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_icd_codes = pd.read_csv(\n",
        "    \"/content/drive/My Drive/DLH Final Project/mimic3/DIAGNOSES_ICD.csv\")"
      ],
      "metadata": {
        "id": "0DQMAoiAPJyh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get top #50 ICD9 codes "
      ],
      "metadata": {
        "id": "wIKf6j0HArw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = df_icd_codes[\"ICD9_CODE\"].value_counts().head(50)\n",
        "top_icd_codes = counts.index.to_list()"
      ],
      "metadata": {
        "id": "jNY4o2-_PsJD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter data to include admimission with top 50 diseases only and group and reorganize data in the following format <subject_id, hadm_id, [icd_code1, icd_code2 ...]>"
      ],
      "metadata": {
        "id": "3wSpzZYNpeIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_admissions_with_top_diseases = \\\n",
        "df_icd_codes[df_icd_codes[\"ICD9_CODE\"].isin(top_icd_codes)]\n",
        "\n",
        "df_admissions_with_top_diseases = \\\n",
        "df_admissions_with_top_diseases.groupby(\n",
        "['SUBJECT_ID', 'HADM_ID'])['ICD9_CODE'].apply(\n",
        "        list).to_frame().reset_index()"
      ],
      "metadata": {
        "id": "zCBDPURVB2C5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now select discharge summaries for the admimissions that contain atleast one of the top #50 ICD codes."
      ],
      "metadata": {
        "id": "5lLEQXITBIyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset = pd.merge(df, df_admissions_with_top_diseases, \n",
        "                       on=[\"SUBJECT_ID\", \"HADM_ID\"])\n",
        "\n",
        "df_dataset = df_dataset[df_dataset[\"CATEGORY\"] \n",
        "                          == 'Discharge summary'].reset_index()\n",
        "# free up some memory\n",
        "# del df"
      ],
      "metadata": {
        "id": "BGIpZW0wfKaO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "mJmeYMT3xiTE",
        "outputId": "09983523-2eff-4844-81cd-b4b2b5e5b333"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
              "0      0     174       22532  167853.0  2151-08-04       NaN       NaN   \n",
              "1      1     170       22532  167853.0  2151-08-04       NaN       NaN   \n",
              "2     32     175       13702  107527.0  2118-06-14       NaN       NaN   \n",
              "\n",
              "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
              "0  Discharge summary      Report   NaN      NaN   \n",
              "1  Discharge summary      Report   NaN      NaN   \n",
              "2  Discharge summary      Report   NaN      NaN   \n",
              "\n",
              "                                                TEXT  \\\n",
              "0  Admission Date:  [**2151-7-16**]       Dischar...   \n",
              "1  Admission Date:  [**2151-7-16**]       Dischar...   \n",
              "2  Admission Date:  [**2118-6-2**]       Discharg...   \n",
              "\n",
              "                       ICD9_CODE  \\\n",
              "0      [42731, 2762, 5070, 5119]   \n",
              "1      [42731, 2762, 5070, 5119]   \n",
              "2  [51881, 486, 2761, 2449, 311]   \n",
              "\n",
              "                                   ICD9_CODE_ENCODED  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
              "\n",
              "                                            SYMPTOMS  \n",
              "0  [Admission, Date, Discharge, Date, Service, AD...  \n",
              "1  [Admission, Date, Discharge, Date, HISTORY, OF...  \n",
              "2  [Admission, Date, Discharge, Date, Date, Birth...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25804e82-a26e-4c25-80af-39543a99d6a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>ROW_ID</th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>CHARTDATE</th>\n",
              "      <th>CHARTTIME</th>\n",
              "      <th>STORETIME</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>CGID</th>\n",
              "      <th>ISERROR</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "      <th>ICD9_CODE_ENCODED</th>\n",
              "      <th>SYMPTOMS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>22532</td>\n",
              "      <td>167853.0</td>\n",
              "      <td>2151-08-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
              "      <td>[42731, 2762, 5070, 5119]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[Admission, Date, Discharge, Date, Service, AD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>22532</td>\n",
              "      <td>167853.0</td>\n",
              "      <td>2151-08-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
              "      <td>[42731, 2762, 5070, 5119]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[Admission, Date, Discharge, Date, HISTORY, OF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32</td>\n",
              "      <td>175</td>\n",
              "      <td>13702</td>\n",
              "      <td>107527.0</td>\n",
              "      <td>2118-06-14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
              "      <td>[51881, 486, 2761, 2449, 311]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
              "      <td>[Admission, Date, Discharge, Date, Date, Birth...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25804e82-a26e-4c25-80af-39543a99d6a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25804e82-a26e-4c25-80af-39543a99d6a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25804e82-a26e-4c25-80af-39543a99d6a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to covert the ICD9 column to multi-hot encoding, we keep the old column with list of codes and added and new column with multi-hot encoding representation."
      ],
      "metadata": {
        "id": "hj5A2EJRqEzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_top_icd_codes = sorted(top_icd_codes)\n",
        "icd_code_to_idx = dict((k, v) for v, k in enumerate(sorted_top_icd_codes))"
      ],
      "metadata": {
        "id": "n-MxiQuQTZWm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new col to be added to dataframe\n",
        "multi_hot_ecoding_col = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  icd_codes = df_dataset.iloc[idx]['ICD9_CODE']\n",
        "  encoding = [0] * 50\n",
        "  for code in icd_codes:\n",
        "    encoding[icd_code_to_idx[code]] = 1    \n",
        "  multi_hot_ecoding_col.append(encoding)\n",
        "\n",
        "# new add a new column with multi-hot encoding.\n",
        "df_dataset['ICD9_CODE_ENCODED'] = multi_hot_ecoding_col"
      ],
      "metadata": {
        "id": "S7vIzsO9V-63"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract symptoms from the text. Note: currently we treat all tokens as symptoms need to add all the filters discussed in the paper later. So we added a column called \"SYMPTOMS\" which is simply tokenized form of \"TEXT\" after basic sanitization."
      ],
      "metadata": {
        "id": "rAtNNVUmCdw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgen = MySentences(df_dataset)\n",
        "symptom_col = list()\n",
        "for s in sgen:\n",
        "  symptom_col.append(s)\n",
        "\n",
        "# add the new column to the dataset.\n",
        "df_dataset[\"SYMPTOMS\"] = symptom_col"
      ],
      "metadata": {
        "id": "GFO96uEPsVC6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Word2Vec Embeddings"
      ],
      "metadata": {
        "id": "RIwaO1C1td27"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg-GmTrg0i6h"
      },
      "source": [
        "Word2Vec training using gensim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xElMsqPx0sc9"
      },
      "outputs": [],
      "source": [
        "# NOTE: commenting this part so that we dont run this by mistake.\n",
        "\n",
        "# import gensim\n",
        "# sgen = MySentences(df_dataset) # a memory-friendly iterator\n",
        "# model = gensim.models.Word2Vec(sgen, min_count=5, workers=4, sample=1e-05)\n",
        "# model.save(\"/content/drive/My Drive/DLH Final Project/mimic3/word2vec-4.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct dataset with Word2Vec embeddings"
      ],
      "metadata": {
        "id": "crLZigFVcbeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec.load('/content/drive/My Drive/DLH Final Project/mimic3/word2vec-4.model')"
      ],
      "metadata": {
        "id": "CE5ABBKOcw21"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_word2vec = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  # ignore words in not vocabulary\n",
        "  symptoms = df_dataset[\"SYMPTOMS\"][idx]\n",
        "  symptoms_emb = [model.wv[s] for s in symptoms if s in model.wv]\n",
        "  X_word2vec.append(symptoms_emb)\n",
        "\n",
        "# pad the dataset.\n",
        "# X_word2vec = pad_dataset(X_word2vec)"
      ],
      "metadata": {
        "id": "YQu3AEBEfbF3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# pfile = open(\"/content/drive/My Drive/DLH Final Project/X_word2vec\", \"ab\")\n",
        "# pickle.dump(X_word2vec, pfile)\n",
        "# pfile.close()"
      ],
      "metadata": {
        "id": "QTY-rPP6l2zJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct data with TF-IDF encoding"
      ],
      "metadata": {
        "id": "V8Q5MAs2xjDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "vocab_size = len(model.wv)\n",
        "tf = np.zeros((len(model.wv), len(top_icd_codes)))\n",
        "\n",
        "\n",
        "for idx in range(len(df_dataset)):\n",
        "  # XXX: TODO currently we treat all tokens from \"TEXT\" as sypmtoms\n",
        "  # get the icd codes for this discharge summary\n",
        "  symptoms = df_dataset['SYMPTOMS'][idx]\n",
        "  icd_codes = df_dataset['ICD9_CODE'][idx]\n",
        "  # create a cross product of symptoms and icd codes\n",
        "  # and update tf matrix. tf matrix keeps count of how many \n",
        "  # (i.e frequency) times <symptom, icd code> pair occur in our dataset.\n",
        "  for pair in itertools.product(symptoms, icd_codes):\n",
        "    # update count of each (symptom, icd_code) pair to compute TF\n",
        "    if pair[0] in model.wv:\n",
        "      tf[model.wv.get_index(pair[0])][icd_code_to_idx[pair[1]]] += 1\n",
        "\n",
        "# Complete the TF-IDF matrix computation.\n",
        "# Compute the number of ICD Codes (i.e diseaes) each \n",
        "# symptom is associated with.\n",
        "D_i = np.sum(tf > 0, axis=1)\n",
        "print(D_i.shape)\n",
        "\n",
        "log_N_Di = np.log(len(top_icd_codes)/D_i)\n",
        "tf_idf = (tf.T * log_N_Di).T\n",
        "print(tf_idf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOGw0qxSxrZ3",
        "outputId": "ea18e4aa-9942-4176-8fe5-f17551dc1282"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64259,)\n",
            "(64259, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the X_tfidf dataset\n",
        "X_tf_idf = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  symptoms = df_dataset[\"SYMPTOMS\"][idx]\n",
        "  # get tf-idf vector for each symptom\n",
        "  # ignore words in not vocabulary\n",
        "  symptoms_tf_idf = [tf_idf[model.wv.get_index(s)] \\\n",
        "                     for s in symptoms if s in model.wv]\n",
        "  X_tf_idf.append(symptoms_tf_idf)\n",
        "\n",
        "# pad the dataset.\n",
        "# X_tf_idf = pad_dataset(X_tf_idf)"
      ],
      "metadata": {
        "id": "W-9C5XBuiOJ3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# pfile = open(\"/content/drive/My Drive/DLH Final Project/X_tf_idf\", \"ab\")\n",
        "# pickle.dump(tf_idf, pfile)\n",
        "# pfile.close()"
      ],
      "metadata": {
        "id": "E3afwJciiW59"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct Y (Multihot Encoding)"
      ],
      "metadata": {
        "id": "ckHf55_ylpmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-hot encoding for ICD codes diagnosed.\n",
        "y = df_dataset['ICD9_CODE_ENCODED'].to_list()"
      ],
      "metadata": {
        "id": "qwrW5WOPkBPd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_word2vec))\n",
        "print(len((X_tf_idf)))\n",
        "print(len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP4e2hJU4S6B",
        "outputId": "21110313-3b6c-41ab-85f7-6aba943bba46"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55988\n",
            "55988\n",
            "55988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Dataset and DataLoaders"
      ],
      "metadata": {
        "id": "D0madEdCl7w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(data):\n",
        "  x_w2v, x_tidf, y_batch = zip(*data)\n",
        "  x_w2v = pad_dataset(x_w2v)\n",
        "  x_tidf = pad_dataset(x_tidf)\n",
        "  y_batch = torch.FloatTensor(y_batch)\n",
        "  if torch.cuda.is_available():\n",
        "    x_w2v.cuda()\n",
        "    x_tidf.cuda()\n",
        "    y_batch.cuda()\n",
        "\n",
        "  return x_w2v, x_tidf, y_batch\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X_w2v, X_tfidf, y):              \n",
        "    self.X_w2v = X_w2v\n",
        "    self.X_tfidf = X_tfidf\n",
        "    self.y = y\n",
        "    \n",
        "  def __len__(self):                \n",
        "    return len(self.y)\n",
        "    \n",
        "  def __getitem__(self, index):          \n",
        "    # your code here\n",
        "    return self.X_w2v[index], self.X_tfidf[index], self.y[index]\n",
        "\n",
        "dataset = CustomDataset(X_word2vec, X_tf_idf, y)\n",
        "\n",
        "split = int(len(dataset)*0.8)\n",
        "lengths = [split, len(dataset) - split]\n",
        "train_dataset, test_dataset = random_split(dataset, lengths)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=400, \n",
        "                          collate_fn=collate_fn)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=400, \n",
        "                         collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "O5HoLixIdZq_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "yilnzXZgi8RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: drop out rate?"
      ],
      "metadata": {
        "id": "lI6PPCn_ZvGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, output_dim):   \n",
        "    super(BiLSTM, self).__init__()\n",
        "    self.lstm = nn.LSTM(input_size=input_dim, \n",
        "                        hidden_size=embedding_dim,\n",
        "                        num_layers=1,\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    self.linear = nn.Linear(embedding_dim*2, \n",
        "                            output_dim)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    out, (hn, cn) = self.lstm(X)    \n",
        "    emb = torch.mean(out, dim=1)\n",
        "    output = torch.sigmoid(self.linear(emb))\n",
        "    return output"
      ],
      "metadata": {
        "id": "RpByc-wrjQ6A"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiseasePredictionModel(nn.Module):\n",
        "  def __init__(self, weight=0.4):    \n",
        "    super(DiseasePredictionModel, self).__init__()\n",
        "    self.weight = 0.4    \n",
        "    self.w2v_lstm = BiLSTM(input_dim=100, embedding_dim=50, output_dim=50)\n",
        "    self.tf_idf_lstm = BiLSTM(input_dim=50, embedding_dim=50, output_dim=50)\n",
        "  \n",
        "  def forward(self, X_w2v, X_tidf):\n",
        "    pred1 = self.w2v_lstm(X_w2v)\n",
        "    pred2 = self.tf_idf_lstm(X_tidf)\n",
        "    # compute the weighted average of predictions\n",
        "    # from the 2 models.\n",
        "    return self.weight * pred1 + (1-self.weight) * pred2"
      ],
      "metadata": {
        "id": "z6v9DR1lm34D"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "wT5_eTcAfyzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DiseasePredictionModel()\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "UYzSUxVr969Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of trainable parameters"
      ],
      "metadata": {
        "id": "FK2BvToZUSZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1qtWBgO-Fi0",
        "outputId": "d524e972-5bdf-448d-ff1b-54ed7b890185"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111700"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "print(psutil.Process().memory_info())\n",
        "print(psutil.virtual_memory())\n",
        "print(torch.cuda.memory_allocated())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw0gBNo8P80l",
        "outputId": "91ce72b1-53fc-4170-b7d1-5da01fd8d7e1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pmem(rss=37108588544, vms=51358666752, shared=831455232, text=4620288, lib=0, data=46858481664, dirty=0)\n",
            "svmem(total=54767017984, available=27296813056, percent=50.2, used=38035439616, free=13423247360, active=27743240192, inactive=13057179648, buffers=113516544, cached=3194814464, shared=1228800, slab=300662784)\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "main_memory_usage = list()\n",
        "gpu_memory_usage = list()\n",
        "gpu_time = list()\n",
        "train_loss = list()\n",
        "\n",
        "for e in range(3):\n",
        "  model.train()\n",
        "  epoc_train_loss = 0\n",
        "  main_memory_before = psutil.virtual_memory().used\n",
        "  gpu_memory_before = torch.cuda.memory_allocated()\n",
        "  start_time = time.time()\n",
        "\n",
        "  # iterate over data in mini batches.\n",
        "  for x_w2v, x_tidf, y_batch in train_loader:    \n",
        "    model.zero_grad()\n",
        "    pred = model(x_w2v, x_tidf)\n",
        "    l = loss(pred, y_batch)\n",
        "    l.backward()\n",
        "    optimizer.step()    \n",
        "    epoc_train_loss += l.item()\n",
        "    break\n",
        "    \n",
        "  # print epoc level training loss.\n",
        "  print(f\"epoc: {e}: Train Loss: {epoc_train_loss/len(train_loader)}\")\n",
        "  \n",
        "  # collect cpu and memory stats.\n",
        "  memory_used = psutil.virtual_memory().used - main_memory_before\n",
        "  gpu_memory_used = torch.cuda.memory_allocated() - gpu_memory_before\n",
        "  run_time = time.time() - start_time\n",
        "  print(f\"time: {run_time} memory_used: {memory_used} gpu_memory_used: {gpu_memory_used}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  train_loss.append(epoc_train_loss/len(train_loader))\n",
        "  main_memory_usage.append(memory_used)\n",
        "  gpu_memory_usage.append(gpu_memory_used)\n",
        "  gpu_time.append(run_time)\n",
        "  # end of one epoc\n",
        "\n",
        "# save the model\n",
        "torch.save(model.state_dict(), get_model_file_name())\n",
        "# print and collect stats.\n",
        "print(psutil.virtual_memory())\n",
        "\n",
        "stats = {\n",
        "    \"gpu_mem\": gpu_memory_usage,\n",
        "    \"main_mem\": main_memory_usage,\n",
        "    \"gpu_time\": gpu_time,\n",
        "    \"vmm_info\": psutil.virtual_memory()\n",
        "}\n",
        "\n",
        "with open(get_stats_file_name(), \"ab\") as sfile:\n",
        "  pickle.dump(stats, sfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djf3IOU68k9G",
        "outputId": "83f4da5c-4334-4a70-e3e7-4b1dfcad53ec"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoc: 0: Train Loss: 0.00619165226817131\n",
            "time: 48.229336738586426 memory_used: 5558087680 gpu_memory_used: 0\n",
            "\n",
            "\n",
            "epoc: 1: Train Loss: 0.0061918071338108605\n",
            "time: 75.82482695579529 memory_used: 1195679744 gpu_memory_used: 0\n",
            "\n",
            "\n",
            "epoc: 2: Train Loss: 0.006191427154200417\n",
            "time: 41.74704194068909 memory_used: 375164928 gpu_memory_used: 0\n",
            "\n",
            "\n",
            "svmem(total=54767017984, available=25736839168, percent=53.0, used=46413266944, free=6575026176, active=29362491392, inactive=18333179904, buffers=97980416, cached=1680744448, shared=1228800, slab=253501440)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "9Y7iNxjCcgOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = DiseasePredictionModel()\n",
        "# model.load_state_dict(\n",
        "#    torch.load(\"/content/drive/My Drive/DLH Final Project/model\"))\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "model.eval()\n",
        "y_pred_all = list()\n",
        "y_true_all = list()\n",
        "\n",
        "for x_w2v, x_tidf, y_batch in test_loader:\n",
        "  y_pred = model(x_w2v, x_tidf)\n",
        "  y_pred = y_pred > 0.2\n",
        "  y_pred_all.extend(y_pred.detach().to('cpu').numpy())\n",
        "  y_true_all.extend(y_batch.detach().to('cpu').numpy())\n",
        "  break\n",
        "\n",
        "p1, r1, f1, s1 = precision_recall_fscore_support(y_true_all, y_pred_all, \n",
        "                                                 average=\"micro\")\n",
        "print(f\"Micro Averaging. Precision: {p1}, Recall: {r1}, F1 Score: {f1}\")\n",
        "\n",
        "p2, r2, f2, s2 = precision_recall_fscore_support(y_true_all, y_pred_all, \n",
        "                                                 average=\"macro\")\n",
        "\n",
        "print(f\"Macro Averaging. Precision: {p2}, Recall: {r2}, F1 Score: {f2}\")\n",
        "\n",
        "results = {\n",
        "    \"micro\": [p1, r1, f1],\n",
        "    \"macro\": [p2, r2, f2]\n",
        "}\n",
        "\n",
        "with open(get_results_file_name(), \"ab\") as rfile:\n",
        "  pickle.dump(results, rfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuYDS46qcfbH",
        "outputId": "1f210e4c-55d6-4035-c276-7ba820c1cc0d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Micro Averaging. Precision: 0.078, Recall: 1.0, F1 Score: 0.14471243042671614\n",
            "Macro Averaging. Precision: 0.078, Recall: 1.0, F1 Score: 0.14471243042671614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS598 Deep Learning For Healthcare Final Project",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}