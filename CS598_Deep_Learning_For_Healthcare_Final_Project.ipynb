{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amyth18/CS598-Deep-Learning-Final-Project/blob/main/CS598_Deep_Learning_For_Healthcare_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ],
      "metadata": {
        "id": "p1kHa9ZOaHbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we provide our implementation for a disease prediction model based on discharge summary text. The implementation is based on the paper titled \"[A disease inference method based on symptom extraction and bidirectional Long Short Term Memory networks](https://https://pubmed.ncbi.nlm.nih.gov/31301375/)\" by Donglin Guo et al.\n",
        "\n",
        "The notebook is divided in 4 parts.\n",
        "1. Data Preprocessing\n",
        "2. Feature Engineering\n",
        "3. Model Training\n",
        "4. Model Evaluation\n",
        "\n",
        "The data preprocessing step needs to be performed only once and the output of this step can be used to run the other sections any number of times.\n",
        "\n",
        "We have tested this notebook in Google Colab pro+ environment. We highly recommend using GPU when training the model.\n",
        "\n",
        "We have used the MIMIC III dataset for training and testing our model, we specifically we need the `NOTEVENTS.csv` and `DIAGNOSES_ICD.csv` files to make this model work.\n",
        "\n",
        "We have used Google Drive as our presistence layer. If you want to use any other storage then you will have to modify the storage paths in the cells accordingly."
      ],
      "metadata": {
        "id": "JTasl4qafFG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ],
      "metadata": {
        "id": "WZAYNZiE-_z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the required packages"
      ],
      "metadata": {
        "id": "PKAq_yUVG8M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gensim --upgrade\n",
        "! pip install psutil\n",
        "! pip install transformers"
      ],
      "metadata": {
        "id": "EHtTRNjY6fjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "metadata": {
        "id": "yZM4PBDMRCc_"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the Google Drive into colab environment. The Google Drive contains our dataset as well acts as persistence for intermdiate data, model and results."
      ],
      "metadata": {
        "id": "ZM16Y04aHB5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFlP8qR9EAEW",
        "outputId": "f37000b6-270f-4fae-cb0a-045516931dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the base path of the project"
      ],
      "metadata": {
        "id": "TlEASa_slIgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_PATH = \"/content/drive/My Drive/DLH Final Project/\""
      ],
      "metadata": {
        "id": "AiRRN0vElQ7k"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZrO8Ao004k3"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are primarily interested in the following 2 files/tables from the MIMIC III dataset.\n",
        "1.   NOTESEVENTS.csv (context discharge summary in \"TEXT\" field for each hospital admission.)\n",
        "2.   DIAGNOSES_ICD.csv (contains ICD9 codes for conditions diagnosed in an admimission)\n",
        "\n"
      ],
      "metadata": {
        "id": "t3Bw9AC1Hh0w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "pcubO8rgEqXh",
        "outputId": "b598bd6d-abed-4668-836f-520d9e593b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SUBJECT_ID   HADM_ID                                               TEXT\n",
              "0       22532  167853.0  Admission Date:  [**2151-7-16**]       Dischar...\n",
              "1       13702  107527.0  Admission Date:  [**2118-6-2**]       Discharg...\n",
              "2       13702  167118.0  Admission Date:  [**2119-5-4**]              D..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d08b1a5f-42bd-4e5a-8304-b94cfa1c252e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22532</td>\n",
              "      <td>167853.0</td>\n",
              "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13702</td>\n",
              "      <td>107527.0</td>\n",
              "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13702</td>\n",
              "      <td>167118.0</td>\n",
              "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d08b1a5f-42bd-4e5a-8304-b94cfa1c252e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d08b1a5f-42bd-4e5a-8304-b94cfa1c252e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d08b1a5f-42bd-4e5a-8304-b94cfa1c252e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/DLH Final Project/mimic3/NOTEEVENTS.csv\")\n",
        "df[[\"SUBJECT_ID\", \"HADM_ID\", \"TEXT\"]].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_icd_codes = pd.read_csv(\n",
        "    \"/content/drive/My Drive/DLH Final Project/mimic3/DIAGNOSES_ICD.csv\")\n",
        "\n",
        "df_icd_codes[[\"SUBJECT_ID\", \"HADM_ID\", \"ICD9_CODE\"]].head(3)"
      ],
      "metadata": {
        "id": "0DQMAoiAPJyh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8b3b96e8-c10f-4192-c888-c7a812561cf5"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SUBJECT_ID  HADM_ID ICD9_CODE\n",
              "0         109   172335     40301\n",
              "1         109   172335       486\n",
              "2         109   172335     58281"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-752603f2-da09-4f1b-b391-f9c52be44549\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>109</td>\n",
              "      <td>172335</td>\n",
              "      <td>40301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>109</td>\n",
              "      <td>172335</td>\n",
              "      <td>486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>109</td>\n",
              "      <td>172335</td>\n",
              "      <td>58281</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-752603f2-da09-4f1b-b391-f9c52be44549')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-752603f2-da09-4f1b-b391-f9c52be44549 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-752603f2-da09-4f1b-b391-f9c52be44549');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASN9TUHWgnz7"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "In this section we perform the following pre-processing steps on out data set and produce a dataframe that is then used for feature engineering in the next section.\n",
        "\n",
        "1.   We first find the top #50 ICD codes (i.e top 50 conditions that are commonly diagnosed in admissions)\n",
        "\n",
        "2.   We then select only those adminisions from `df_icd_codes` dataframe that contain atleat one of the top #50 ICD9 codes.\n",
        "\n",
        "3. We then perform inner join on the filtered `df_icd_codes` to the `df` (i.e. NOTEVENTS.csv) to select discharge summary text from only those admimissions that contain at least one top #50 ICD9 code.\n",
        "\n",
        "4. We then generate Word2Vec embeddings using all the filtered discharge summaries using Gensim. This will be used later in feature engineering.\n",
        "\n",
        "5. We then extract only the symptom phrases from the discharge summaries using a pre-trained BERT model. The symptoms will then form the input features (represented in 2 forms) for our prediction model. This step is performed Feature Engineering section.\n",
        "\n",
        "The following diagram shows the data pre-processing pipeline.\n",
        "\n",
        "![picture](https://drive.google.com/file/d/1deg7uoKN9cd7LWleztiWTLCgBKg2r1KT/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Routines For Data Pre-Processing"
      ],
      "metadata": {
        "id": "kxdU3qT1k3m7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performs data cleaning, curation and symptom extraction using pre-trained BERT model on clinical text."
      ],
      "metadata": {
        "id": "Zz9WPSrjOCoP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "TV7TblwfIxta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502b755b-2040-4586-a7b3-de42efdfc4dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "import re\n",
        "import nltk\n",
        "from transformers import AutoTokenizer, pipeline,  AutoModelForTokenClassification\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "eng_stop_words =  stopwords.words('english')\n",
        "\n",
        "class MySentences(object):\n",
        "    def __init__(self, dframe):\n",
        "        self.dframe = dframe\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\n",
        "            \"samrawal/bert-base-uncased_clinical-ner\")\n",
        "        model = AutoModelForTokenClassification.from_pretrained(\n",
        "            \"samrawal/bert-base-uncased_clinical-ner\")\n",
        "        symptom_extractor = pipeline('ner', model=model, tokenizer=tokenizer,\n",
        "                                     device=0)\n",
        "        text_anno = symptom_extractor(self.dframe[\"TEXT\"].tolist(), \n",
        "                                           batch_size=256)\n",
        "        self.data = list(zip(text_anno, self.dframe[\"TEXT\"].tolist()))        \n",
        "\n",
        "    # TODO: Keeping only alpha numeric characters and spaces for now.\n",
        "    # need to make this better. Find some good libraries.\n",
        "    def sanitize_text(self, text):\n",
        "      test = text.strip()\n",
        "      text = re.sub(r'\\s\\s+', ' ', text)\n",
        "      text = re.sub(r'[^a-zA-z0-9\\/\\.\\?\\!\\s;,\\'\\-]', '', text)\n",
        "      text = re.sub(r'[\\.\\-\\/\\?\\!;,]', ' ', text)\n",
        "      text = re.sub(r'[\\[\\]]', '', text)\n",
        "      return text\n",
        "\n",
        "    def extract_symptoms(self, input_anno_text) -> List[str]:\n",
        "      \"\"\"\n",
        "      The method extract the symptom phrases from the input\n",
        "      \"\"\"\n",
        "      extractions, text = input_anno_text\n",
        "      span_extract = []\n",
        "      for extract in extractions:\n",
        "        if 'problem' in extract['entity']:\n",
        "          span_extract.append((extract['start'], extract['end']))\n",
        "\n",
        "      # Check if this span_extract is empty\n",
        "      if not span_extract:\n",
        "        return []\n",
        "      \n",
        "      span_st = span_extract[0][0]\n",
        "      final_span = []\n",
        "      final_end = span_extract[0][1]\n",
        "      for idx, (st, end) in enumerate(span_extract):\n",
        "        if idx == 0:\n",
        "          continue\n",
        "        if st - span_extract[idx-1][1] <= 2:\n",
        "          final_end = end\n",
        "          if idx == len(span_extract) - 1:\n",
        "            final_span.append((span_st, final_end))\n",
        "        else:\n",
        "          final_span.append((span_st, final_end))\n",
        "          span_st = st\n",
        "          final_end = end\n",
        "\n",
        "      text_extracts = [text[st:end].replace(\"\\n\", \" \") for st, end in final_span]\n",
        "      return text_extracts\n",
        "\n",
        "    # TODO: adding some basic checks again need to make it better.\n",
        "    def sanitize_words(self, sentence):\n",
        "      return [w for w in sentence if w not in eng_stop_words and not w.isdigit()]\n",
        "\n",
        "    def __iter__(self):\n",
        "        for idx in range(len(self.dframe)):\n",
        "          symptoms = \" \".join(self.extract_symptoms(self.data[idx]))\n",
        "          text = self.sanitize_text(symptoms)\n",
        "          yield self.sanitize_words(text.split())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Word2Vec Embeddings"
      ],
      "metadata": {
        "id": "RIwaO1C1td27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We generate Word2Vec embeddings on the raw discharge summary text. These embeddings will be used later when we extract only the symptoms from the dischage summaries and generate Word2Vec embedding for those symptoms. \n",
        "\n",
        "Note: This step needs to be done only once before start the of project."
      ],
      "metadata": {
        "id": "taHoY3XCAv3J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "xElMsqPx0sc9"
      },
      "outputs": [],
      "source": [
        "# NOTE: commenting this part so that we dont run this by mistake.\n",
        "# we only need to perform this once at the start of the project.\n",
        "\n",
        "# import gensim\n",
        "# sgen = MySentences(df_dataset) # a memory-friendly iterator\n",
        "# model = gensim.models.Word2Vec(sgen, min_count=5, workers=4, sample=1e-05)\n",
        "# model.save(\"/content/drive/My Drive/DLH Final Project/mimic3/word2vec-4.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Filtering and Tranformation"
      ],
      "metadata": {
        "id": "n1xDk_pMlBPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get top #50 ICD9 codes "
      ],
      "metadata": {
        "id": "wIKf6j0HArw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = df_icd_codes[\"ICD9_CODE\"].value_counts().head(50)\n",
        "top_icd_codes = counts.index.to_list()"
      ],
      "metadata": {
        "id": "jNY4o2-_PsJD"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_top_icd_codes = sorted(top_icd_codes)\n",
        "icd_code_to_idx = dict((k, v) for v, k in enumerate(sorted_top_icd_codes))"
      ],
      "metadata": {
        "id": "n-MxiQuQTZWm"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter data to include admimission with top 50 diseases only and group and reorganize data in the following format <subject_id, hadm_id, [icd_code1, icd_code2 ...]>"
      ],
      "metadata": {
        "id": "3wSpzZYNpeIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_admissions_with_top_diseases = \\\n",
        "df_icd_codes[df_icd_codes[\"ICD9_CODE\"].isin(top_icd_codes)]\n",
        "\n",
        "df_admissions_with_top_diseases = \\\n",
        "df_admissions_with_top_diseases.groupby(\n",
        "['SUBJECT_ID', 'HADM_ID'])['ICD9_CODE'].apply(\n",
        "        list).to_frame().reset_index()"
      ],
      "metadata": {
        "id": "zCBDPURVB2C5"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now select discharge summaries for the admimissions that contain atleast one of the top #50 ICD codes."
      ],
      "metadata": {
        "id": "5lLEQXITBIyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset = pd.merge(df, df_admissions_with_top_diseases, \n",
        "                       on=[\"SUBJECT_ID\", \"HADM_ID\"])\n",
        "\n",
        "df_dataset = df_dataset[df_dataset[\"CATEGORY\"] \n",
        "                          == 'Discharge summary'].reset_index()\n",
        "# free up some memory\n",
        "# del df"
      ],
      "metadata": {
        "id": "BGIpZW0wfKaO"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So our dataset now looks like this."
      ],
      "metadata": {
        "id": "z9cOWY2jQHsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset[[\"SUBJECT_ID\", \"HADM_ID\", \"TEXT\", \"ICD9_CODE\"]].head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "mJmeYMT3xiTE",
        "outputId": "6acf9e66-7c86-4bb9-dc12-5e4bea280e62"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SUBJECT_ID   HADM_ID                                               TEXT  \\\n",
              "0       22532  167853.0  Admission Date:  [**2151-7-16**]       Dischar...   \n",
              "1       22532  167853.0  Admission Date:  [**2151-7-16**]       Dischar...   \n",
              "2       13702  107527.0  Admission Date:  [**2118-6-2**]       Discharg...   \n",
              "\n",
              "                       ICD9_CODE  \n",
              "0      [42731, 2762, 5070, 5119]  \n",
              "1      [42731, 2762, 5070, 5119]  \n",
              "2  [51881, 486, 2761, 2449, 311]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db2c849e-6e0a-4db6-b4d9-caf2321a9245\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22532</td>\n",
              "      <td>167853.0</td>\n",
              "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
              "      <td>[42731, 2762, 5070, 5119]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22532</td>\n",
              "      <td>167853.0</td>\n",
              "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
              "      <td>[42731, 2762, 5070, 5119]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13702</td>\n",
              "      <td>107527.0</td>\n",
              "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
              "      <td>[51881, 486, 2761, 2449, 311]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db2c849e-6e0a-4db6-b4d9-caf2321a9245')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db2c849e-6e0a-4db6-b4d9-caf2321a9245 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db2c849e-6e0a-4db6-b4d9-caf2321a9245');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, extract only the phrases related to symptoms using pre-trained BERT model on clinical test from the discharge summary. In the paper the authoes have used MetaMap for this, we could not access MetaMap in time so we are using an alternate method. We intend to run our experiment with MetaMap during our final implementation.\n",
        "\n"
      ],
      "metadata": {
        "id": "rAtNNVUmCdw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "sgen = MySentences(df_dataset)\n",
        "symptom_col = list()\n",
        "for s in tqdm(sgen):\n",
        "  symptom_col.append(s)\n",
        "\n",
        "# add the new column to the dataset.\n",
        "df_dataset[\"SYMPTOMS\"] = symptom_col"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFO96uEPsVC6",
        "outputId": "e48d7bee-3d21-49af-a99a-aad192681882"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "55988it [00:10, 5203.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset = df_dataset[df_dataset.apply(lambda x: len(x.SYMPTOMS) > 0, axis=1)]\n",
        "df_dataset = df_dataset.reset_index()\n",
        "df_dataset.to_csv(\"/content/drive/My Drive/DLH Final Project/kbr_df_dataset.csv\")\n",
        "\n",
        "del sgen"
      ],
      "metadata": {
        "id": "VG1jN7Xvr4b1"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So our final dataset after all the pre-processing looks like this."
      ],
      "metadata": {
        "id": "iGDHZtPsQVIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset[[\"SUBJECT_ID\", \"HADM_ID\", \"SYMPTOMS\", \"ICD9_CODE\"]].head(3)"
      ],
      "metadata": {
        "id": "tQgJ2BQbQcCb",
        "outputId": "eb7ee6b6-7501-4459-efd4-9e9048128e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SUBJECT_ID   HADM_ID                                           SYMPTOMS  \\\n",
              "0       22532  167853.0  [cavitary, lesions, left, lung, apex, infectio...   \n",
              "1       22532  167853.0  [productive, cough, lb, weight, loss, shortnes...   \n",
              "2       13702  107527.0  [emphysema, shortness, breath, COPD, flare, Fe...   \n",
              "\n",
              "                       ICD9_CODE  \n",
              "0      [42731, 2762, 5070, 5119]  \n",
              "1      [42731, 2762, 5070, 5119]  \n",
              "2  [51881, 486, 2761, 2449, 311]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-849914d6-fddc-448a-9d3d-4541f75cda17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>SYMPTOMS</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22532</td>\n",
              "      <td>167853.0</td>\n",
              "      <td>[cavitary, lesions, left, lung, apex, infectio...</td>\n",
              "      <td>[42731, 2762, 5070, 5119]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22532</td>\n",
              "      <td>167853.0</td>\n",
              "      <td>[productive, cough, lb, weight, loss, shortnes...</td>\n",
              "      <td>[42731, 2762, 5070, 5119]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13702</td>\n",
              "      <td>107527.0</td>\n",
              "      <td>[emphysema, shortness, breath, COPD, flare, Fe...</td>\n",
              "      <td>[51881, 486, 2761, 2449, 311]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-849914d6-fddc-448a-9d3d-4541f75cda17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-849914d6-fddc-448a-9d3d-4541f75cda17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-849914d6-fddc-448a-9d3d-4541f75cda17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "EX9tul509p_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data preprocessing steps need to be performed only once during the project (unless of course we change any data preprocessing steps). Now we load the pre-processed data and start constructing our 2 forms of feature vectors for each symptom extracted as mentioned in the paper."
      ],
      "metadata": {
        "id": "xobHFgpe-NZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct Dataset With Word2Vec embeddings"
      ],
      "metadata": {
        "id": "crLZigFVcbeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we generate our first form of vector representation for symptoms. We generate a `Word2Vec` embedding (using the Gensim model we trained previously in the data pre-processing step) for each symptom extracted from the discharge summary. Each input then becomes a sequence of `Word2Vec` embedding.\n",
        "\n",
        "`[emb1, emb2 ...]`"
      ],
      "metadata": {
        "id": "8CRNJ9hkTUfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec.load('/content/drive/My Drive/DLH Final Project/mimic3/word2vec-4.model')"
      ],
      "metadata": {
        "id": "CE5ABBKOcw21"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_word2vec = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  # ignore words in not vocabulary\n",
        "  symptoms = df_dataset[\"SYMPTOMS\"][idx]\n",
        "  symptoms_emb = [model.wv[s] for s in symptoms if s in model.wv]\n",
        "  X_word2vec.append(symptoms_emb)\n"
      ],
      "metadata": {
        "id": "YQu3AEBEfbF3"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct Dataset With TF-IDF encoding"
      ],
      "metadata": {
        "id": "V8Q5MAs2xjDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we generate our second form for symptom representation. We compute a TF-IDF like metric for each symptom extracted and then represent each symtom with its TF-IDF vector. So our input in this form looks like a sequence of TF-IDF vectors.\n",
        "\n",
        "`[td-idf(s1), tf-idf(s2) ...]`\n",
        "\n",
        "where each `tf-idf` vector is of length of 50 (for top#50 diseases) and `s1, s2 ...` are symtoms."
      ],
      "metadata": {
        "id": "sVlfp23-VbA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "vocab_size = len(model.wv)\n",
        "tf = np.zeros((len(model.wv), len(top_icd_codes)))\n",
        "\n",
        "\n",
        "for idx in range(len(df_dataset)):\n",
        "  # XXX: TODO currently we treat all tokens from \"TEXT\" as sypmtoms\n",
        "  # get the icd codes for this discharge summary\n",
        "  symptoms = df_dataset['SYMPTOMS'][idx]\n",
        "  icd_codes = df_dataset['ICD9_CODE'][idx]\n",
        "  # create a cross product of symptoms and icd codes\n",
        "  # and update tf matrix. tf matrix keeps count of how many \n",
        "  # (i.e frequency) times <symptom, icd code> pair occur in our dataset.\n",
        "  for pair in itertools.product(symptoms, icd_codes):\n",
        "    # update count of each (symptom, icd_code) pair to compute TF\n",
        "    if pair[0] in model.wv:\n",
        "      tf[model.wv.get_index(pair[0])][icd_code_to_idx[pair[1]]] += 1\n",
        "\n",
        "# Complete the TF-IDF matrix computation.\n",
        "# Compute the number of ICD Codes (i.e diseaes) each \n",
        "# symptom is associated with.\n",
        "D_i = np.sum(tf > 0, axis=1)\n",
        "print(D_i.shape)\n",
        "\n",
        "log_N_Di = np.log(len(top_icd_codes)/D_i)\n",
        "tf_idf = (tf.T * log_N_Di).T\n",
        "print(tf_idf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOGw0qxSxrZ3",
        "outputId": "5d7de6a5-a62d-4870-8171-45fbad6ef50a"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64259,)\n",
            "(64259, 50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in multiply\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use the above generated `tf-idf` matrix to convert each symtom into a `TF-IDF` vector."
      ],
      "metadata": {
        "id": "AUUKYmpgWbMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the X_tfidf dataset\n",
        "X_tf_idf = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  symptoms = df_dataset[\"SYMPTOMS\"][idx]\n",
        "  # get tf-idf vector for each symptom\n",
        "  # ignore words in not vocabulary\n",
        "  symptoms_tf_idf = [tf_idf[model.wv.get_index(s)] \\\n",
        "                     for s in symptoms if s in model.wv]\n",
        "  X_tf_idf.append(symptoms_tf_idf)\n"
      ],
      "metadata": {
        "id": "W-9C5XBuiOJ3"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct Y (as Multi-hot Encoding)"
      ],
      "metadata": {
        "id": "ckHf55_ylpmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As this is a multi-label classification problem (i.e predicting one or more diseases from top #50 most commonly occuring diseases) we use a multi-hot representation for our response variable.\n",
        "\n",
        "We covert the ICD9 column to multi-hot encoding, we keep the old column with list of codes and add a new column with multi-hot encoding representation."
      ],
      "metadata": {
        "id": "hj5A2EJRqEzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# new col to be added to dataframe\n",
        "multi_hot_ecoding_col = list()\n",
        "for idx in range(len(df_dataset)):\n",
        "  icd_codes = df_dataset.iloc[idx]['ICD9_CODE']\n",
        "  encoding = [0] * 50\n",
        "  for code in icd_codes:\n",
        "    encoding[icd_code_to_idx[code]] = 1    \n",
        "  multi_hot_ecoding_col.append(encoding)\n",
        "\n",
        "# new add a new column with multi-hot encoding.\n",
        "df_dataset['ICD9_CODE_ENCODED'] = multi_hot_ecoding_col"
      ],
      "metadata": {
        "id": "S7vIzsO9V-63"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-hot encoding for ICD codes diagnosed.\n",
        "y = df_dataset['ICD9_CODE_ENCODED'].to_list()"
      ],
      "metadata": {
        "id": "qwrW5WOPkBPd"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_word2vec))\n",
        "print(len((X_tf_idf)))\n",
        "print(len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP4e2hJU4S6B",
        "outputId": "95854ab7-da1a-4058-a0d8-079ab7283310"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54939\n",
            "54939\n",
            "54939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Dataset and DataLoaders"
      ],
      "metadata": {
        "id": "D0madEdCl7w1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility to created padded dataset so that we an perform batch processing of data in model traning and evaluation."
      ],
      "metadata": {
        "id": "RP7Vg2W1OTH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_dataset(dataset, vec_size):\n",
        "  seq_lengths = list()\n",
        "\n",
        "  for idx in range(len(dataset)):\n",
        "    seq_lengths.append(len(dataset[idx]))\n",
        "  max_seq_length = max(seq_lengths)\n",
        "\n",
        "  padded_dataset = torch.zeros([len(dataset), max_seq_length, vec_size], \n",
        "                               dtype=torch.float)\n",
        "  for i in range(len(dataset)):\n",
        "    for j in range(len(dataset[i])):\n",
        "      padded_dataset[i][j] = torch.FloatTensor(dataset[i][j])\n",
        "  \n",
        "  return padded_dataset"
      ],
      "metadata": {
        "id": "81XPts3oIlGR"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we define our dataset and data loaders for both train and test dataset."
      ],
      "metadata": {
        "id": "Oaas5utnXfvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(data):\n",
        "  x_w2v, x_tidf, y_batch = zip(*data)\n",
        "  x_w2v = pad_dataset(x_w2v, 100)\n",
        "  x_tidf = pad_dataset(x_tidf, 50)\n",
        "  y_batch = torch.FloatTensor(y_batch)\n",
        "  x_w2v = x_w2v.cuda() if torch.cuda.is_available() else x_w2v\n",
        "  x_tidf = x_tidf.cuda() if torch.cuda.is_available() else x_tidf\n",
        "  y_batch = y_batch.cuda() if torch.cuda.is_available() else y_batch\n",
        "\n",
        "  return x_w2v, x_tidf, y_batch\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X_w2v, X_tfidf, y):              \n",
        "    self.X_w2v = X_w2v\n",
        "    self.X_tfidf = X_tfidf\n",
        "    self.y = y\n",
        "    \n",
        "  def __len__(self):                \n",
        "    return len(self.y)\n",
        "    \n",
        "  def __getitem__(self, index):          \n",
        "    # your code here\n",
        "    return self.X_w2v[index], self.X_tfidf[index], self.y[index]\n",
        "\n",
        "dataset = CustomDataset(X_word2vec, X_tf_idf, y)\n",
        "\n",
        "split = int(len(dataset)*0.8)\n",
        "lengths = [split, len(dataset) - split]\n",
        "train_dataset, test_dataset = random_split(dataset, lengths)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=400, \n",
        "                          collate_fn=collate_fn)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=400, \n",
        "                         collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "O5HoLixIdZq_"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "yilnzXZgi8RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model consiste of the following components\n",
        "\n",
        "\n",
        "1. A BiLSTM model trained on Word2Vec representation of symptoms\n",
        "2. Another BiLSTM model trained on TF-IDF representation of symptoms.\n",
        "3. A weighted averate of predictions from the above models.\n",
        "\n",
        "The following diagram shows the architecture of the model.\n",
        "\n",
        "![picture](https://drive.google.com/file/d/1uENAQjwBme9TUeIcZDrDerLHi84W3QLA/view)\n",
        "\n"
      ],
      "metadata": {
        "id": "N8bt5oAfYbIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODOs: \n",
        "1.   Add a dropout layer.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lI6PPCn_ZvGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, output_dim):   \n",
        "    super(BiLSTM, self).__init__()\n",
        "    self.lstm = nn.LSTM(input_size=input_dim, \n",
        "                        hidden_size=embedding_dim,\n",
        "                        num_layers=1,\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    self.linear = nn.Linear(embedding_dim*2, \n",
        "                            output_dim)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    out, (hn, cn) = self.lstm(X)    \n",
        "    emb = torch.mean(out, dim=1)\n",
        "    output = torch.sigmoid(self.linear(emb))\n",
        "    return output"
      ],
      "metadata": {
        "id": "RpByc-wrjQ6A"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiseasePredictionModel(nn.Module):\n",
        "  def __init__(self, weight=0.4):    \n",
        "    super(DiseasePredictionModel, self).__init__()\n",
        "    self.weight = 0.4    \n",
        "    self.w2v_lstm = BiLSTM(input_dim=100, embedding_dim=50, output_dim=50)\n",
        "    self.tf_idf_lstm = BiLSTM(input_dim=50, embedding_dim=50, output_dim=50)\n",
        "  \n",
        "  def forward(self, X_w2v, X_tidf):\n",
        "    pred1 = self.w2v_lstm(X_w2v)\n",
        "    pred2 = self.tf_idf_lstm(X_tidf)\n",
        "    # compute the weighted average of predictions\n",
        "    # from the 2 models.\n",
        "    return self.weight * pred1 + (1-self.weight) * pred2"
      ],
      "metadata": {
        "id": "z6v9DR1lm34D"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "wT5_eTcAfyzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility to generate file names to store various results during training."
      ],
      "metadata": {
        "id": "0X6j9urpPLDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "def get_model_file_name():\n",
        "  return \"/content/drive/My Drive/DLH Final Project/models/model-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")\n",
        "\n",
        "def get_stats_file_name():\n",
        "  return \"/content/drive/My Drive/DLH Final Project/stats/stats-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")\n",
        "\n",
        "def get_results_file_name():\n",
        "  return \"/content/drive/My Drive/DLH Final Project/stats/results-\" + \\\n",
        "                  datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\n",
        "                      \"%d-%m-%Y-%H-%M-%S\")"
      ],
      "metadata": {
        "id": "pZ5obtEaX68T"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the model for training. We use Binary Cross Entropy as loss function and Adam optimizer with learning rate of 0.001 (as recommeded in the paper)"
      ],
      "metadata": {
        "id": "py-1OnbnZN_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DiseasePredictionModel()\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "UYzSUxVr969Q"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of trainable parameters"
      ],
      "metadata": {
        "id": "FK2BvToZUSZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1qtWBgO-Fi0",
        "outputId": "3377964d-63fb-466b-f195-85fa722ba790"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111700"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "main_memory_usage = list()\n",
        "gpu_memory_usage = list()\n",
        "gpu_time = list()\n",
        "train_loss = list()\n",
        "\n",
        "for e in range(100):\n",
        "  model.train()\n",
        "  epoc_train_loss = 0\n",
        "  main_memory_before = psutil.virtual_memory().used\n",
        "  gpu_memory_before = torch.cuda.memory_allocated()\n",
        "  start_time = time.time()\n",
        "\n",
        "  # iterate over data in mini batches.\n",
        "  for x_w2v, x_tidf, y_batch in train_loader:    \n",
        "    model.zero_grad()\n",
        "    pred = model(x_w2v, x_tidf)\n",
        "    l = loss(pred, y_batch)\n",
        "    l.backward()\n",
        "    optimizer.step()    \n",
        "    epoc_train_loss += l.item()\n",
        "    \n",
        "  # print epoc level training loss.\n",
        "  print(f\"epoc: {e}: Train Loss: {epoc_train_loss/len(train_loader)}\")\n",
        "  \n",
        "  # collect cpu and memory stats.\n",
        "  memory_used = psutil.virtual_memory().used\n",
        "  gpu_memory_used = torch.cuda.memory_allocated()\n",
        "  run_time = time.time() - start_time\n",
        "  print(f\"time: {run_time} memory_used: {memory_used} gpu_memory_used: {gpu_memory_used}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  train_loss.append(epoc_train_loss/len(train_loader))\n",
        "  main_memory_usage.append(memory_used)\n",
        "  gpu_memory_usage.append(gpu_memory_used)\n",
        "  gpu_time.append(run_time)\n",
        "  # end of one epoc\n",
        "\n",
        "# save the model\n",
        "torch.save(model.state_dict(), get_model_file_name())\n",
        "# print and collect stats.\n",
        "print(psutil.virtual_memory())\n",
        "\n",
        "stats = {\n",
        "    \"gpu_mem\": gpu_memory_usage,\n",
        "    \"main_mem\": main_memory_usage,\n",
        "    \"gpu_time\": gpu_time,\n",
        "    \"vmm_info\": psutil.virtual_memory()\n",
        "}\n",
        "\n",
        "with open(get_stats_file_name(), \"ab\") as sfile:\n",
        "  pickle.dump(stats, sfile)"
      ],
      "metadata": {
        "id": "djf3IOU68k9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "9Y7iNxjCcgOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is multi-class classication problem we use micro and macro averaring strategy for evaluation performance. We use the `scikit-learn ` utility to compute these metrics.\n",
        "\n",
        "We set the prediction threshold (i.e. value above we mark a disease as present) as 0.2 as per the recommendation in the paper."
      ],
      "metadata": {
        "id": "bwQuUVHcZfvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = DiseasePredictionModel()\n",
        "# model.load_state_dict(\n",
        "#    torch.load(\"/content/drive/My Drive/DLH Final Project/model\"))\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "model.eval()\n",
        "y_pred_all = list()\n",
        "y_true_all = list()\n",
        "\n",
        "for x_w2v, x_tidf, y_batch in test_loader:\n",
        "  y_pred = model(x_w2v, x_tidf)\n",
        "  y_pred = y_pred > 0.2\n",
        "  y_pred_all.extend(y_pred.detach().to('cpu').numpy())\n",
        "  y_true_all.extend(y_batch.detach().to('cpu').numpy())\n",
        "\n",
        "p1, r1, f1, s1 = precision_recall_fscore_support(y_true_all, y_pred_all, \n",
        "                                                 average=\"micro\")\n",
        "print(f\"Micro Averaging. Precision: {p1}, Recall: {r1}, F1 Score: {f1}\")\n",
        "\n",
        "p2, r2, f2, s2 = precision_recall_fscore_support(y_true_all, y_pred_all, \n",
        "                                                 average=\"macro\")\n",
        "\n",
        "print(f\"Macro Averaging. Precision: {p2}, Recall: {r2}, F1 Score: {f2}\")\n",
        "\n",
        "results = {\n",
        "    \"micro\": [p1, r1, f1],\n",
        "    \"macro\": [p2, r2, f2]\n",
        "}\n",
        "\n",
        "with open(get_results_file_name(), \"ab\") as rfile:\n",
        "  pickle.dump(results, rfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuYDS46qcfbH",
        "outputId": "16939b2e-b286-4a6d-af05-c134de01329c"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Micro Averaging. Precision: 0.4067211625794732, Recall: 0.626907461850763, F1 Score: 0.493361978736297\n",
            "Macro Averaging. Precision: 0.3675190234878991, Recall: 0.5367868273260352, F1 Score: 0.4295094437724686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize Resource Utilization"
      ],
      "metadata": {
        "id": "CtexOT1xjaIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def get_object(path):\n",
        "  obj = None\n",
        "  with open(path, \"rb\") as p:\n",
        "    obj = pickle.load(p)\n",
        "\n",
        "  return obj\n",
        "\n",
        "def to_gb(b):\n",
        "  return round(b/(1024*1024*1024), 2)\n",
        "\n",
        "def to_mb(b):\n",
        "  return round(b/(1024*1024), 2)"
      ],
      "metadata": {
        "id": "YAwHYm87kDV-"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l \"{PROJECT_PATH}/stats\""
      ],
      "metadata": {
        "id": "T6UnzuuhlavP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# system configuration\n",
        "import psutil\n",
        "\n",
        "print(f\"Total GPU Memory: {to_gb(torch.cuda.get_device_properties(0).total_memory)} GB\")\n",
        "print(f\"Total CPU Memory: {to_gb(psutil.virtual_memory().total)} GB\")"
      ],
      "metadata": {
        "id": "Ywq47aa7qcby",
        "outputId": "0e937530-807c-45ee-ed32-0fe9921012ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total GPU Memory: 15.9 GB\n",
            "Total CPU Memory: 51.01 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "stats = get_object(f\"{PROJECT_PATH}/stats/stats-17-04-2022-02-35-12\")\n",
        "print(f\"Average GPU Memory Used: {to_mb(np.mean(stats['gpu_mem']))} MB\")\n",
        "print(f\"Average Main Memory Used: {to_gb(np.mean(stats['main_mem']))} GB\")\n",
        "print(f\"Average GPU Time (per epoc): {np.mean(stats['gpu_time']):.2f} sec\")\n",
        "print(f\"Total GPU Time: {np.sum(stats['gpu_time']):.2f} sec\")"
      ],
      "metadata": {
        "id": "qXQfSeCQjZN-",
        "outputId": "0a49b354-3e2f-40d8-de20-fca815a6e3d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average GPU Memory Used: 39.68 MB\n",
            "Average Main Memory Used: 10.39 GB\n",
            "Average GPU Time (per epoc): 35.34 sec\n",
            "Total GPU Time: 3533.87 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a_mi = np.array([0.496, 0.564, 0.528])\n",
        "o_mi = np.array([0.406, 0.626, 0.493])\n",
        "print(((a_mi - o_mi).T / a_mi) * 100)\n",
        "\n",
        "a_ma = np.array([0.464, 0.463, 0.448])\n",
        "o_ma = np.array([0.367, 0.536, 0.429])\n",
        "print(((a_ma - o_ma).T / a_ma) * 100)"
      ],
      "metadata": {
        "id": "CWmPQOaG2ATa",
        "outputId": "bb96316b-0da5-49a8-8bb6-23bb0d087e30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 18.14516129 -10.9929078    6.62878788]\n",
            "[ 20.90517241 -15.76673866   4.24107143]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS598 Deep Learning For Healthcare Final Project",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}